{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1. **Set file paths and options** in the **Setup** cell:\n",
    "   - `iptm_file_path`: Path to the IPTM vs. PEAK file (required).\n",
    "   - `spoc_file_path`: Path to the SPOC score file (optional).\n",
    "   - `SPOC_analysis`: Set to `True` if you want to do SPOC-based analysis (requires a valid SPOC file), otherwise `False`.\n",
    "   - `output_dir`: Where to save charts and selected data (defaults to creating an \"analysis\" folder next to your IPTM file).\n",
    "\n",
    "2. **Run the notebook cells in order**:\n",
    "   - The second cell loads the IPTM data and checks whether to proceed with SPOC or basic analysis.\n",
    "   - If SPOC analysis is enabled and the file is provided, the subsequent cells will merge data and show the SPOC-based chart.\n",
    "   - Otherwise, you'll see the basic IPTM vs. PEAK chart.\n",
    "\n",
    "3. **Interact with the charts**:\n",
    "   - Use **Lasso/Box select** to label points persistently.\n",
    "   - Use the **Search** widget to highlight points by partial name.\n",
    "   - **Clear** labels or search highlights as needed.\n",
    "   - **Save** the plot as HTML/PDF or **export** selected data as a CSV.\n",
    "\n",
    "4. **Check the output directory** for your saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 1: BASIC SETUP ===\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "from plotly.graph_objs import FigureWidget\n",
    "\n",
    "# ---------------- USER INPUTS ----------------\n",
    "# Required: path to the IPTM vs. PEAK file\n",
    "iptm_file_path = \"IPTM_vs_PTM.txt\"\n",
    "\n",
    "\n",
    "# Optional: path to the SPOC file\n",
    "#Set None if not available\n",
    "spoc_file_path = \"spoc_dir_SPOC_analysis.csv\"\n",
    "\n",
    "# Boolean flag indicating whether you want to do SPOC analysis\n",
    "SPOC_analysis = True  # or False\n",
    "\n",
    "# Output directory (default is a subfolder 'analysis' next to the IPTM file)\n",
    "# If you want to override, set output_dir = \"/your/desired/output\"\n",
    "default_base = os.path.dirname(iptm_file_path)  # Folder of the IPTM file\n",
    "default_out = os.path.join(default_base, \"analysis\")\n",
    "output_dir = default_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hoverfields and fetch data about Protein complex association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will fetch complex info if ANY of these conditions are met:\n",
      "  IPTM_max >= 0.5\n",
      "  scaled_PEAKavg >= 0.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0906ecb1e2480aaf42d1edc41ef154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Complex Info:', options=('Fetch Complex Data', 'Skip Complex Data'), value='Fetch C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================\n",
    "# A) USER CONFIGURATION FOR THRESHOLD-BASED FETCH\n",
    "# ==========================\n",
    "# Dictionary mapping columns to the threshold above which complex info will be fetched.\n",
    "# e.g. If \"IPTM_max\" >= 0.5 OR \"scaled_PEAKavg\" >= 1.2, fetch complex info. \n",
    "# If the column doesn't exist or is NaN, it won't trigger a fetch.\n",
    "FETCH_COLUMNS = {\n",
    "    \"IPTM_max\": 0.5,\n",
    "    \"scaled_PEAKavg\": 0.75\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Will fetch complex info if ANY of these conditions are met:\\n\"\n",
    "    + \"\\n\".join([f\"  {col} >= {thresh}\" for col, thresh in FETCH_COLUMNS.items()])\n",
    ")\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "fetch_toggle = widgets.ToggleButtons(\n",
    "    options=['Fetch Complex Data', 'Skip Complex Data'],\n",
    "    description='Complex Info:'\n",
    ")\n",
    "\n",
    "display(fetch_toggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPTM file path   : IPTM_vs_PTM.txt\n",
      "SPOC file path   : spoc_dir_SPOC_analysis.csv\n",
      "SPOC_analysis    : True\n",
      "Output directory : analysis\n",
      "Loaded IPTM DataFrame with shape: (831, 10)\n",
      "Created 'IPTM_max' column with the maximum IPTM score for each row.\n",
      "SPOC analysis is True, and a SPOC file is provided. Proceeding with SPOC-based code...\n",
      "SPOC DataFrame shape: (210, 30)\n",
      "Merged DataFrame shape: (831, 41)\n",
      "Skipping fetch...\n",
      "Parallel fetching of UniProt and ComplexPortal data complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: IPTM & SPOC Data Loading, Complex Portal Retrieval, and Hover Widget Setup\n",
    "# ==========================\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import concurrent.futures\n",
    "\n",
    "# 1) Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 2) Print diagnostic info\n",
    "print(\"IPTM file path   :\", iptm_file_path)\n",
    "print(\"SPOC file path   :\", spoc_file_path)\n",
    "print(\"SPOC_analysis    :\", SPOC_analysis)\n",
    "print(\"Output directory :\", output_dir)\n",
    "\n",
    "\n",
    "# We will check fetch_toggle.value later to see if the user selected \"Skip\".\n",
    "\n",
    "# ==========================\n",
    "# B) Class & Function Definitions\n",
    "# ==========================\n",
    "\n",
    "# --------------------------\n",
    "# B1) ProteinComplexInfo class\n",
    "# --------------------------\n",
    "class ProteinComplexInfo:\n",
    "    def __init__(self, uniprot_id, uniprot_cache, complex_cache):\n",
    "        \"\"\"\n",
    "        Initialize with a UniProt ID and retrieve its JSON record\n",
    "        using the provided caches.\n",
    "        \"\"\"\n",
    "        self.uniprot_id = uniprot_id\n",
    "        self.uniprot_cache = uniprot_cache\n",
    "        self.complex_cache = complex_cache\n",
    "        \n",
    "        # Use a cached fetch\n",
    "        self.uniprot_data = self.get_uniprot_data(uniprot_id)\n",
    "        self.complex_ids = self.extract_complex_ids(self.uniprot_data) if self.uniprot_data else []\n",
    "\n",
    "    def get_uniprot_data(self, uniprot_id):\n",
    "        if uniprot_id in self.uniprot_cache:\n",
    "            return self.uniprot_cache[uniprot_id]\n",
    "        \n",
    "        url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.json\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            # Store in cache\n",
    "            self.uniprot_cache[uniprot_id] = data\n",
    "            return data\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error retrieving data for {uniprot_id}: {e}\")\n",
    "            self.uniprot_cache[uniprot_id] = None\n",
    "            return None\n",
    "\n",
    "    def extract_complex_ids(self, uniprot_data):\n",
    "        complexes = []\n",
    "        for xref in uniprot_data.get(\"uniProtKBCrossReferences\", []):\n",
    "            if xref.get(\"database\") == \"ComplexPortal\":\n",
    "                comp_id = xref.get(\"id\", \"N/A\")\n",
    "                complexes.append(comp_id)\n",
    "        return complexes\n",
    "\n",
    "    def get_complex_details_json(self, complex_id):\n",
    "        if complex_id in self.complex_cache:\n",
    "            return self.complex_cache[complex_id]\n",
    "\n",
    "        url = f\"https://www.ebi.ac.uk/intact/complex-ws/complex/{complex_id}\"\n",
    "        headers = {\"accept\": \"application/json\"}\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            self.complex_cache[complex_id] = data\n",
    "            return data\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error retrieving details for complex {complex_id}: {e}\")\n",
    "            self.complex_cache[complex_id] = None\n",
    "            return None\n",
    "        except json.decoder.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error for complex {complex_id}: {e}\")\n",
    "            self.complex_cache[complex_id] = None\n",
    "            return None\n",
    "\n",
    "    def get_all_complex_info(self):\n",
    "        complex_info_list = []\n",
    "        for comp_id in self.complex_ids:\n",
    "            details = self.get_complex_details_json(comp_id)\n",
    "            if details:\n",
    "                name = details.get(\"name\", \"No name provided\")\n",
    "                functions = details.get(\"functions\", [])\n",
    "                complex_info_list.append({\n",
    "                    \"complex_id\": comp_id,\n",
    "                    \"name\": name,\n",
    "                    \"functions\": functions\n",
    "                })\n",
    "        return complex_info_list\n",
    "    \n",
    "# --------------------------\n",
    "# B2) Helper to retrieve complex info from a UniProt ID\n",
    "# --------------------------\n",
    "def get_complex_info_from_target(target_uniprot_id, uniprot_cache, complex_cache):\n",
    "    pci = ProteinComplexInfo(target_uniprot_id, uniprot_cache, complex_cache)\n",
    "    complex_info_list = pci.get_all_complex_info()\n",
    "    if complex_info_list:\n",
    "        # For simplicity, take the first complex if multiple exist\n",
    "        first_complex = complex_info_list[0]\n",
    "        complex_name = first_complex.get(\"name\", \"\")\n",
    "        functions = first_complex.get(\"functions\", [])\n",
    "        functions_str = \"; \".join(functions) if functions else \"\"\n",
    "        return (complex_name, functions_str)\n",
    "    else:\n",
    "        return (None, None)\n",
    "\n",
    "# --------------------------\n",
    "# B3) Parse target UniProt ID and short name from the \"NAME\" field\n",
    "# --------------------------\n",
    "def parse_target_info(full_name):\n",
    "    \"\"\"\n",
    "    Given a string like:\n",
    "      \"76_sp-Q92610-ZN592_HUMAN_vs_sp-Q13889-TF2H3_HUMAN\"\n",
    "    return (target_uniprot_id, name).\n",
    "\n",
    "    Example: (\"Q13889\", \"TF2H3\")\n",
    "    \"\"\"\n",
    "    if pd.isnull(full_name):\n",
    "        return (None, None)\n",
    "    try:\n",
    "        parts = full_name.split(\"_vs_\")\n",
    "        if len(parts) < 2:\n",
    "            return (None, None)\n",
    "        target_part = parts[1]  # e.g., \"sp-Q13889-TF2H3_HUMAN\"\n",
    "        chunks = target_part.split(\"-\")\n",
    "        if len(chunks) < 3:\n",
    "            return (None, target_part)\n",
    "        target_uniprot_id = chunks[1]  # e.g., Q13889\n",
    "        name = chunks[2].split(\"_\")[0]  # e.g., TF2H3\n",
    "        return (target_uniprot_id, name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing '{full_name}': {e}\")\n",
    "        return (None, None)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# B4) Extract the max IPTM score from the \"IPTM\" column\n",
    "# --------------------------\n",
    "def extract_max_from_iptm(value):\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        parts = str(value).split(\":\")\n",
    "        nums = []\n",
    "        for part in parts:\n",
    "            try:\n",
    "                nums.append(float(part))\n",
    "            except:\n",
    "                pass\n",
    "        return max(nums) if nums else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# B5) Logic to decide if complex info should be fetched, based on user-defined thresholds\n",
    "# --------------------------\n",
    "def should_fetch_complex_info(row, fetch_config):\n",
    "    \"\"\"\n",
    "    Returns True if ANY of the user-specified columns in `fetch_config`\n",
    "    meets or exceeds its threshold. Otherwise returns False.\n",
    "\n",
    "    - `fetch_config` is a dict: {column_name: threshold_value, ...}\n",
    "    - If the column is missing or NaN, it won't trigger a fetch.\n",
    "    \"\"\"\n",
    "    for col, threshold in fetch_config.items():\n",
    "        if col in row and pd.notnull(row[col]):\n",
    "            if row[col] >= threshold:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def fetch_complex_info_threshold(row):\n",
    "    \"\"\"\n",
    "    Return (complex_name, complex_function) only if should_fetch_complex_info\n",
    "    returns True. Otherwise, (None, None).\n",
    "    \"\"\"\n",
    "    target_id = row[\"target_uniprot_id\"]\n",
    "    if pd.isnull(target_id):\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "    # Check the user-defined thresholds\n",
    "    if not should_fetch_complex_info(row, FETCH_COLUMNS):\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "    return pd.Series(get_complex_info_from_target(target_id))\n",
    "\n",
    "# ==========================\n",
    "# C) Main Data Processing\n",
    "# ==========================\n",
    "\n",
    "# 1) Load the IPTM data\n",
    "df_iptm = pd.read_csv(iptm_file_path, sep=\"\\t\")\n",
    "print(\"Loaded IPTM DataFrame with shape:\", df_iptm.shape)\n",
    "\n",
    "# 2) Create an IPTM_max column\n",
    "df_iptm[\"IPTM_max\"] = df_iptm[\"IPTM\"].apply(extract_max_from_iptm)\n",
    "print(\"Created 'IPTM_max' column with the maximum IPTM score for each row.\")\n",
    "\n",
    "# 3) Merge with SPOC data if provided\n",
    "if SPOC_analysis and spoc_file_path is not None:\n",
    "    print(\"SPOC analysis is True, and a SPOC file is provided. Proceeding with SPOC-based code...\")\n",
    "    df_spoc = pd.read_csv(spoc_file_path)\n",
    "    print(\"SPOC DataFrame shape:\", df_spoc.shape)\n",
    "    \n",
    "    # Merge\n",
    "    merged_df = pd.merge(\n",
    "        df_iptm,\n",
    "        df_spoc,\n",
    "        left_on=\"NAME\",\n",
    "        right_on=\"complex_name\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    print(\"Merged DataFrame shape:\", merged_df.shape)\n",
    "else:\n",
    "    print(\"Either SPOC_analysis is False or no SPOC file provided.\")\n",
    "    print(\"Proceeding without SPOC merge (basic bubble chart).\")\n",
    "    merged_df = df_iptm.copy()\n",
    "\n",
    "\n",
    "# Cell 2\n",
    "if fetch_toggle.value == 'Skip Complex Data':\n",
    "    print(\"Skipping fetch...\")\n",
    "    merged_df[\"complex\"] = None\n",
    "    merged_df[\"complex_info\"] = None\n",
    "else:\n",
    "    print(\"Fetching data...\")\n",
    "    # 4) Let the user know we will fetch complex info\n",
    "    msg = (\n",
    "        f\"Fetching complex associations if any of these conditions are met:\\n\" +\n",
    "        \"\\n\".join([f\"  - {col} >= {thresh}\" for col, thresh in FETCH_COLUMNS.items()]) +\n",
    "        \"\\nPlease be patient or increase thresholds for fetchhing Complex info...\"\n",
    "    )\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "\n",
    "# 5) Parse (target_uniprot_id, name) from \"NAME\"\n",
    "merged_df[[\"target_uniprot_id\", \"name\"]] = merged_df[\"NAME\"].apply(\n",
    "    lambda x: pd.Series(parse_target_info(x))\n",
    ")\n",
    "\n",
    "#parallel downloading\n",
    "import concurrent.futures\n",
    "\n",
    "UNIPROT_CACHE = {}\n",
    "COMPLEX_DETAILS_CACHE = {}\n",
    "\n",
    "# 1) Figure out which rows pass your thresholds\n",
    "rows_to_fetch = merged_df.apply(lambda r: should_fetch_complex_info(r, FETCH_COLUMNS), axis=1)\n",
    "sub_df = merged_df[rows_to_fetch].copy()\n",
    "\n",
    "# 2) Extract unique UniProt IDs\n",
    "unique_uniprot_ids = sub_df[\"target_uniprot_id\"].dropna().unique()\n",
    "\n",
    "# 3) Parallel fetch UniProt JSON data\n",
    "def fetch_uniprot_and_cache(uniprot_id):\n",
    "    # Re-use or slightly refactor your ProteinComplexInfo code:\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.json\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        UNIPROT_CACHE[uniprot_id] = data\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {uniprot_id}: {e}\")\n",
    "        UNIPROT_CACHE[uniprot_id] = None\n",
    "\n",
    "# Actually run the concurrent fetch\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_uid = {\n",
    "        executor.submit(fetch_uniprot_and_cache, uid): uid\n",
    "        for uid in unique_uniprot_ids\n",
    "    }\n",
    "    for future in concurrent.futures.as_completed(future_to_uid):\n",
    "        uid = future_to_uid[future]\n",
    "        try:\n",
    "            future.result()  # triggers fetch\n",
    "        except Exception as e:\n",
    "            print(f\"Error in future for {uid}: {e}\")\n",
    "\n",
    "# 4) Collect the ComplexPortal IDs from each UniProt record\n",
    "all_complex_ids = set()\n",
    "for uid in unique_uniprot_ids:\n",
    "    record = UNIPROT_CACHE.get(uid)\n",
    "    if record and \"uniProtKBCrossReferences\" in record:\n",
    "        for xref in record[\"uniProtKBCrossReferences\"]:\n",
    "            if xref.get(\"database\") == \"ComplexPortal\":\n",
    "                comp_id = xref.get(\"id\")\n",
    "                if comp_id:\n",
    "                    all_complex_ids.add(comp_id)\n",
    "\n",
    "# 5) Parallel fetch ComplexPortal details\n",
    "def fetch_complexportal_and_cache(comp_id):\n",
    "    url = f\"https://www.ebi.ac.uk/intact/complex-ws/complex/{comp_id}\"\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        COMPLEX_DETAILS_CACHE[comp_id] = r.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching ComplexPortal {comp_id}: {e}\")\n",
    "        COMPLEX_DETAILS_CACHE[comp_id] = None\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_compid = {\n",
    "        executor.submit(fetch_complexportal_and_cache, cid): cid\n",
    "        for cid in all_complex_ids\n",
    "    }\n",
    "    for future in concurrent.futures.as_completed(future_to_compid):\n",
    "        cid = future_to_compid[future]\n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in future for complex {cid}: {e}\")\n",
    "\n",
    "print(\"Parallel fetching of UniProt and ComplexPortal data complete.\")\n",
    "\n",
    "def final_complex_info(row):\n",
    "    \"\"\"\n",
    "    Return (complex_name, functions_str) for the row's target_uniprot_id,\n",
    "    but only if it passes thresholds. We use UNIPROT_CACHE and COMPLEX_DETAILS_CACHE\n",
    "    for quick lookups.\n",
    "    \"\"\"\n",
    "    if pd.isnull(row[\"target_uniprot_id\"]):\n",
    "        return (None, None)\n",
    "    if not should_fetch_complex_info(row, FETCH_COLUMNS):\n",
    "        return (None, None)\n",
    "\n",
    "    # We do a mini-version of get_complex_info_from_target here, \n",
    "    # but purely with the caches:\n",
    "    uid = row[\"target_uniprot_id\"]\n",
    "    uniprot_record = UNIPROT_CACHE.get(uid, {})\n",
    "    if not uniprot_record:\n",
    "        return (None, None)\n",
    "\n",
    "    # Extract complex IDs:\n",
    "    complex_ids = []\n",
    "    for xref in uniprot_record.get(\"uniProtKBCrossReferences\", []):\n",
    "        if xref.get(\"database\") == \"ComplexPortal\":\n",
    "            comp_id = xref.get(\"id\")\n",
    "            if comp_id:\n",
    "                complex_ids.append(comp_id)\n",
    "    if not complex_ids:\n",
    "        return (None, None)\n",
    "\n",
    "    # For simplicity, just take the first one\n",
    "    first_comp_id = complex_ids[0]\n",
    "    complex_record = COMPLEX_DETAILS_CACHE.get(first_comp_id, {})\n",
    "    if not complex_record:\n",
    "        return (None, None)\n",
    "\n",
    "    name = complex_record.get(\"name\", \"\")\n",
    "    functions = complex_record.get(\"functions\", [])\n",
    "    functions_str = \"; \".join(functions) if functions else \"\"\n",
    "    return (name, functions_str)\n",
    "\n",
    "# Finally, assign the columns:\n",
    "merged_df[[\"complex\", \"complex_info\"]] = merged_df.apply(\n",
    "    final_complex_info, axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# D) (Optional) SPOC-Specific Enhancements\n",
    "# ==========================\n",
    "if SPOC_analysis and spoc_file_path is not None:\n",
    "    # Create an \"opacity\" column based on spoc_score (if present)\n",
    "    if \"spoc_score\" in merged_df.columns and merged_df[\"spoc_score\"].notnull().any():\n",
    "        min_score = merged_df[\"spoc_score\"].min()\n",
    "        max_score = 1.0  # forcing maximum to 1.0\n",
    "        def compute_opacity(score):\n",
    "            if pd.isnull(score):\n",
    "                return 0.1\n",
    "            if max_score == min_score:\n",
    "                return 1.0\n",
    "            return 0.1 + (score - min_score) / (max_score - min_score) * (1.0 - 0.1)\n",
    "        merged_df[\"opacity\"] = merged_df[\"spoc_score\"].apply(compute_opacity)\n",
    "    else:\n",
    "        merged_df[\"opacity\"] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: /Volumes/plaschka/shared/data/mass-spec/MS_analysis/protein_annotations/POIs_PolII_Spliceosome_250225_MV.xlsx\n",
      "External DataFrame shape: (534, 16)\n",
      "Showing first 5 rows of external DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Symbol</th>\n",
       "      <th>Complex</th>\n",
       "      <th>Class / family</th>\n",
       "      <th>Other UniProt Accessions</th>\n",
       "      <th>More Aliases from Entrez</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Ensemble Gene ID</th>\n",
       "      <th>Molecular weight from SwissProt</th>\n",
       "      <th>Domains from SwissProt</th>\n",
       "      <th>Motifs from SwissProt</th>\n",
       "      <th>Entrez Gene ID</th>\n",
       "      <th>Full Gene Name from Entrez</th>\n",
       "      <th>UniProt Entry Name</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Pdbs</th>\n",
       "      <th>Compositional AA Bias from SwissProt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAF1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation</td>\n",
       "      <td>P21675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation factor TFIID subunit ...</td>\n",
       "      <td>TAF1_HUMAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TAF2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation</td>\n",
       "      <td>Q6P1X5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation factor TFIID subunit ...</td>\n",
       "      <td>TAF2_HUMAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAF3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation</td>\n",
       "      <td>Q5VWG9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation factor TFIID subunit ...</td>\n",
       "      <td>TAF3_HUMAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TAF4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation</td>\n",
       "      <td>O00268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation factor TFIID subunit ...</td>\n",
       "      <td>TAF4_HUMAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAF5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation</td>\n",
       "      <td>Q15542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transcription initiation factor TFIID subunit ...</td>\n",
       "      <td>TAF5_HUMAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene Symbol Complex            Class / family Other UniProt Accessions  \\\n",
       "0        TAF1     NaN  Transcription initiation                   P21675   \n",
       "1        TAF2     NaN  Transcription initiation                   Q6P1X5   \n",
       "2        TAF3     NaN  Transcription initiation                   Q5VWG9   \n",
       "3        TAF4     NaN  Transcription initiation                   O00268   \n",
       "4        TAF5     NaN  Transcription initiation                   Q15542   \n",
       "\n",
       "   More Aliases from Entrez  Organism  Ensemble Gene ID  \\\n",
       "0                       NaN       NaN               NaN   \n",
       "1                       NaN       NaN               NaN   \n",
       "2                       NaN       NaN               NaN   \n",
       "3                       NaN       NaN               NaN   \n",
       "4                       NaN       NaN               NaN   \n",
       "\n",
       "   Molecular weight from SwissProt  Domains from SwissProt  \\\n",
       "0                              NaN                     NaN   \n",
       "1                              NaN                     NaN   \n",
       "2                              NaN                     NaN   \n",
       "3                              NaN                     NaN   \n",
       "4                              NaN                     NaN   \n",
       "\n",
       "   Motifs from SwissProt  Entrez Gene ID  \\\n",
       "0                    NaN             NaN   \n",
       "1                    NaN             NaN   \n",
       "2                    NaN             NaN   \n",
       "3                    NaN             NaN   \n",
       "4                    NaN             NaN   \n",
       "\n",
       "                          Full Gene Name from Entrez UniProt Entry Name  \\\n",
       "0  Transcription initiation factor TFIID subunit ...         TAF1_HUMAN   \n",
       "1  Transcription initiation factor TFIID subunit ...         TAF2_HUMAN   \n",
       "2  Transcription initiation factor TFIID subunit ...         TAF3_HUMAN   \n",
       "3  Transcription initiation factor TFIID subunit ...         TAF4_HUMAN   \n",
       "4  Transcription initiation factor TFIID subunit ...         TAF5_HUMAN   \n",
       "\n",
       "   Unnamed: 13  Pdbs  Compositional AA Bias from SwissProt  \n",
       "0          NaN   NaN                                   NaN  \n",
       "1          NaN   NaN                                   NaN  \n",
       "2          NaN   NaN                                   NaN  \n",
       "3          NaN   NaN                                   NaN  \n",
       "4          NaN   NaN                                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging on:\n",
      "- Current DF column: target_uniprot_id\n",
      "- External DF column: Other UniProt Accessions\n",
      "Handling multiple IDs in the external file with delimiter: ','\n",
      "Merged DataFrame shape: (831, 62) using how='left'\n"
     ]
    }
   ],
   "source": [
    "#####Merged with annotation file (optional)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/matthias.vorlaender/Library/CloudStorage/OneDrive-VBC/scripts/python/Tools/DataMerger\")\n",
    "\n",
    "from DataMerger import DataFrameMerger\n",
    "#merged_df.head()\n",
    "\n",
    "# Instantiate the merger\n",
    "merger = DataFrameMerger(merged_df)\n",
    "\n",
    "# Set the file path (the file can be CSV, TSV, XLS, or XLSX)\n",
    "merger.set_file_path(\"/Volumes/plaschka/shared/data/mass-spec/MS_analysis/protein_annotations/POIs_PolII_Spliceosome_250225_MV.xlsx\")\n",
    "\n",
    "#Optional\n",
    "#merged_df.head()\n",
    "\n",
    "# Preview the external file\n",
    "merger.preview_file(n=5)\n",
    "\n",
    "##Merge dataframe with external file (i.e protein annotations from MS analysis)\n",
    "merger.set_merge_columns(\n",
    "    df_col='target_uniprot_id',\n",
    "    external_col='Other UniProt Accessions',\n",
    "    multiple_id_delimiter=','\n",
    ")\n",
    "\n",
    "# Perform the merge (e.g., as a left merge)\n",
    "merged_df = merger.merge_data(how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### SPOC Hover-Column Selection"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3ffcdf7f064574a535b343c8c9e0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Hover Columns:', index=(0, 1, 6, 41), layout=Layout(width='400px'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================== E) Build default hover text & interactive widget# ==========================\n",
    "# 1) Default columns for hover\n",
    "default_hover_columns = [\"NAME\", \"IPTM\", \"PEAK\", \"complex\"]\n",
    "# Remove any that don't exist in merged_df\n",
    "default_hover_columns = [c for c in default_hover_columns if c in merged_df.columns]\n",
    "\n",
    "merged_df[\"hover_text\"] = merged_df.apply(\n",
    "    lambda row: \"<br>\".join([f\"{col}: {row[col]}\" for col in default_hover_columns]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 2) Build widget to allow user to update hover columns\n",
    "available_hover_columns = list(merged_df.columns)\n",
    "if default_hover_columns:\n",
    "    preselected = tuple(default_hover_columns)\n",
    "else:\n",
    "    preselected = (available_hover_columns[0],)  # fallback\n",
    "\n",
    "hover_columns_selector = widgets.SelectMultiple(\n",
    "    options=available_hover_columns,\n",
    "    value=preselected,\n",
    "    description=\"Hover Columns:\",\n",
    "    disabled=False,\n",
    "    layout={'width': '400px'}\n",
    ")\n",
    "update_hover_button = widgets.Button(\n",
    "    description=\"Update Hover Info\",\n",
    "    button_style=\"primary\"\n",
    ")\n",
    "\n",
    "def update_hover_info(b):\n",
    "    selected_columns = list(hover_columns_selector.value)\n",
    "    if not selected_columns:\n",
    "        print(\"Please select at least one column for hover info.\")\n",
    "        return\n",
    "    merged_df[\"hover_text\"] = merged_df.apply(\n",
    "        lambda row: \"<br>\".join([f\"{col}: {row[col]}\" for col in selected_columns]),\n",
    "        axis=1\n",
    "    )\n",
    "    print(\"Hover info updated using columns:\", selected_columns)\n",
    "\n",
    "update_hover_button.on_click(update_hover_info)\n",
    "\n",
    "display(Markdown(\"### SPOC Hover-Column Selection\"))\n",
    "display(widgets.HBox([hover_columns_selector, update_hover_button]))\n",
    "\n",
    "# Your 'merged_df' is now ready for further analysis or plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with or without SPOC values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "    **SPOC-Based Plot Instructions:**\n",
       "    1. **Use Lasso/Box select to pick points and persist labels**.\n",
       "    2. (Optional) Search by partial `NAME` using the first box, then clear highlights if needed.\n",
       "    3. **Highlight by index** (the digits before the underscore) using the second box, \n",
       "       e.g. (1,5,12,19=green) (2,9,200=red) (20=blue)\n",
       "    4. Clear persistent labels and/or highlight traces if needed.\n",
       "    5. Save the plot (HTML & PDF) or selected data (CSV).\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d752bade504246d6a84d2ceedffb6a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Search NAME:', layout=Layout(width='400px'), placeholder='Enter par…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28835aa604784a62aeeb27fe52be62b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='(245,22,250,743,690,261,233,229,479,464,107,1,203,660,659,648,363,462,474,475,492,2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475d2037be314efe9a45e0cbdfa1caf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='warning', description='Clear Labels', style=ButtonStyle()),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee2d7ff11664e02b3feff5dd11319cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Filename Suffix:', layout=Layout(width='400px'), placeholder='Add f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc407520ab4414cbb3b7eb750c85d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'customdata': array([['Complex: nan'],\n",
       "                                   ['Complex: nan'],\n",
       "                                   ['Complex: nan'],\n",
       "                                   ...,\n",
       "                                   ['Complex: nan'],\n",
       "                                   ['Complex: nan'],\n",
       "                                   ['Complex: nan']], dtype=object),\n",
       "              'hovertemplate': '%{customdata[0]}<extra></extra>',\n",
       "              'legendgroup': '',\n",
       "              'marker': {'color': [rgba(67,58,129,0.1), rgba(42,120,142,0.1),\n",
       "                                   rgba(70,20,101,0.1), ..., rgba(178,221,45,0.1),\n",
       "                                   rgba(153,216,60,0.1), rgba(175,221,47,0.1)],\n",
       "                         'coloraxis': 'coloraxis',\n",
       "                         'size': array([0.89 , 0.813, 0.647, ..., 0.141, 0.147, 0.127]),\n",
       "                         'sizemode': 'area',\n",
       "                         'sizeref': np.float64(0.002225),\n",
       "                         'symbol': 'circle'},\n",
       "              'mode': 'markers',\n",
       "              'name': '',\n",
       "              'orientation': 'v',\n",
       "              'showlegend': False,\n",
       "              'type': 'scatter',\n",
       "              'uid': '7ca1e60b-1a4b-40f1-85b5-9f161862dc47',\n",
       "              'x': array([0.823, 0.621, 0.926, ..., 0.2  , 0.233, 0.203]),\n",
       "              'xaxis': 'x',\n",
       "              'y': array([0.7448, 0.483 , 0.615 , ..., 0.1324, 0.1366, 0.1196]),\n",
       "              'yaxis': 'y'}],\n",
       "    'layout': {'coloraxis': {'colorbar': {'title': {'text': 'Scaled PEAKavg'}},\n",
       "                             'colorscale': [[0.0, '#fde725'], [0.1111111111111111,\n",
       "                                            '#b5de2b'], [0.2222222222222222,\n",
       "                                            '#6ece58'], [0.3333333333333333,\n",
       "                                            '#35b779'], [0.4444444444444444,\n",
       "                                            '#1f9e89'], [0.5555555555555556,\n",
       "                                            '#26828e'], [0.6666666666666666,\n",
       "                                            '#31688e'], [0.7777777777777778,\n",
       "                                            '#3e4989'], [0.8888888888888888,\n",
       "                                            '#482878'], [1.0, '#440154']]},\n",
       "               'legend': {'itemsizing': 'constant', 'tracegroupgap': 0},\n",
       "               'margin': {'b': 50, 'l': 50, 'r': 50, 't': 50},\n",
       "               'shapes': [{'line': {'color': 'black', 'width': 2},\n",
       "                           'type': 'rect',\n",
       "                           'x0': 0,\n",
       "                           'x1': 1,\n",
       "                           'xref': 'paper',\n",
       "                           'y0': 0,\n",
       "                           'y1': 1,\n",
       "                           'yref': 'paper'}],\n",
       "               'template': '...',\n",
       "               'title': {'text': '(SPOC) IPTM vs. Scaled PEAKavg'},\n",
       "               'xaxis': {'anchor': 'y',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'linecolor': 'black',\n",
       "                         'linewidth': 2,\n",
       "                         'showgrid': False,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'Scaled PEAKavg'}},\n",
       "               'yaxis': {'anchor': 'x',\n",
       "                         'domain': [0.0, 1.0],\n",
       "                         'linecolor': 'black',\n",
       "                         'linewidth': 2,\n",
       "                         'showgrid': False,\n",
       "                         'showline': True,\n",
       "                         'title': {'text': 'IPTMavg'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37b4e4637ba439db746529ddec2a28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='selected_data.csv', description='Save CSV as:', placeholder='Enter file name'), But…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e901218065dc4ba7b72cf3359ca2d779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === STEP 4a: SPOC-BASED BUBBLE CHART ===\n",
    "import re\n",
    "from plotly.colors import sample_colorscale\n",
    "\n",
    "# Global variable to store the current hover column selection.\n",
    "# Initialize with the default hover columns.\n",
    "current_hover_columns = default_hover_columns\n",
    "\n",
    "def update_hover_info(b):\n",
    "    global current_hover_columns\n",
    "    selected_columns = list(hover_columns_selector.value)\n",
    "    if not selected_columns:\n",
    "        print(\"Please select at least one column for hover info.\")\n",
    "        return\n",
    "    current_hover_columns = selected_columns\n",
    "\n",
    "    merged_df[\"hover_text\"] = merged_df.apply(\n",
    "        lambda row: \"<br>\".join([f\"{col}: {row[col]}\" for col in  selected_columns]),\n",
    "        axis=1\n",
    "    )\n",
    "    print(\"Hover info updated using columns:\", selected_columns)\n",
    "\n",
    "update_hover_button.on_click(update_hover_info)\n",
    "\n",
    "def parse_name_field(name_str):\n",
    "    \"\"\"\n",
    "    Given a string of form:\n",
    "       \"76_sp-Q92610-ZN592_HUMAN_vs_sp-Q13889-TF2H3_HUMAN\"\n",
    "    return a dict with:\n",
    "       {\n",
    "         'index': '76',\n",
    "         'protein1': 'sp-Q92610-ZN592_HUMAN',\n",
    "         'protein2': 'sp-Q13889-TF2H3_HUMAN'\n",
    "       }\n",
    "    If parsing fails, returns something fallback with empty strings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split around '_vs_'\n",
    "        parts = name_str.split(\"_vs_\")\n",
    "        left_part = parts[0]  # e.g. \"76_sp-Q92610-ZN592_HUMAN\"\n",
    "        right_part = parts[1] # e.g. \"sp-Q13889-TF2H3_HUMAN\"\n",
    "\n",
    "        # Now split the left_part on the first underscore, to separate index from protein1\n",
    "        left_sub = left_part.split(\"_\", 1)\n",
    "        idx = left_sub[0]  # \"76\"\n",
    "        prot1 = left_sub[1]  # \"sp-Q92610-ZN592_HUMAN\"\n",
    "\n",
    "        return {\n",
    "            \"index\": idx,\n",
    "            \"protein1\": prot1,\n",
    "            \"protein2\": right_part\n",
    "        }\n",
    "    except Exception:\n",
    "        # If something goes wrong, return placeholders\n",
    "        return {\n",
    "            \"index\": \"\",\n",
    "            \"protein1\": \"\",\n",
    "            \"protein2\": \"\"\n",
    "        }\n",
    "\n",
    "def parse_color(color_str):\n",
    "    \"\"\"Converts a hex or rgb(a) color string to (r, g, b).\"\"\"\n",
    "    # This helper is used if you need numeric r,g,b from a string.\n",
    "    # If you only need to pass e.g. \"red\" or \"#ff0000\" to Plotly,\n",
    "    # you can skip converting to (r,g,b). Plotly can handle them directly.\n",
    "    if color_str.startswith(\"#\"):\n",
    "        hex_color = color_str.lstrip(\"#\")\n",
    "        r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "        return r, g, b\n",
    "    elif color_str.startswith(\"rgb\"):\n",
    "        nums = re.findall(r'\\d+', color_str)\n",
    "        r, g, b = tuple(int(n) for n in nums[:3])\n",
    "        return r, g, b\n",
    "    else:\n",
    "        # Try named CSS color (e.g. \"red\", \"blue\") - Plotly accepts those directly\n",
    "        return color_str\n",
    "\n",
    "# Before building the figure, let's ensure 'index' is in merged_df\n",
    "if SPOC_analysis and spoc_file_path is not None:\n",
    "    if \"index\" not in merged_df.columns:\n",
    "        # Parse once for all rows\n",
    "        parsed_info = merged_df[\"NAME\"].apply(parse_name_field).apply(pd.Series)\n",
    "        merged_df = pd.concat([merged_df, parsed_info], axis=1)\n",
    "        # Ensure 'index' column is treated as a string\n",
    "        merged_df[\"index\"] = merged_df[\"index\"].astype(str)\n",
    "\n",
    "    # Build the scatter figure\n",
    "    fig = px.scatter(\n",
    "        merged_df,\n",
    "        x=\"scaled_PEAKavg\",\n",
    "        y=\"IPTMavg\",\n",
    "        size=\"IPTM_max\",    \n",
    "        color=\"scaled_PEAKavg\",\n",
    "        color_continuous_scale=\"viridis_r\",\n",
    "        title=\"(SPOC) IPTM vs. Scaled PEAKavg\",\n",
    "        labels={\"IPTMavg\": \"IPTMavg\", \"scaled_PEAKavg\": \"Scaled PEAKavg\"}\n",
    "    )\n",
    "    # Then insert this snippet next:\n",
    "\n",
    "    # Build color array with custom opacity\n",
    "    min_val = merged_df[\"scaled_PEAKavg\"].min()\n",
    "    max_val = merged_df[\"scaled_PEAKavg\"].max()\n",
    "    if max_val != min_val:\n",
    "        norm = (merged_df[\"scaled_PEAKavg\"] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        norm = merged_df[\"scaled_PEAKavg\"] * 0  # or just 0\n",
    "\n",
    "    base_colors = px.colors.sequential.Viridis_r\n",
    "    rgba_colors = []\n",
    "    for val, opa in zip(norm, merged_df[\"opacity\"]):\n",
    "        color_str = sample_colorscale(base_colors, val)[0]  # returns a color string\n",
    "        try:\n",
    "            r, g, b = parse_color(color_str)\n",
    "            if isinstance(r, str):\n",
    "                # color was a named CSS color\n",
    "                rgba_colors.append(r) \n",
    "            else:\n",
    "                rgba_colors.append(f\"rgba({r},{g},{b},{opa})\")\n",
    "        except:\n",
    "            rgba_colors.append(f\"rgba(0,0,0,{opa})\")\n",
    "\n",
    "    fig.update_traces(\n",
    "        marker=dict(color=rgba_colors),\n",
    "        customdata=merged_df[[\"hover_text\"]].values,\n",
    "        hovertemplate=\"%{customdata[0]}<extra></extra>\"\n",
    "    )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        # Update x and y axes: no grid, with black axis lines.\n",
    "        xaxis=dict(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor='black'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor='black'\n",
    "        ),\n",
    "        # Add a rectangle shape as an outer border.\n",
    "        shapes=[\n",
    "            dict(\n",
    "                type=\"rect\",\n",
    "                xref=\"paper\", yref=\"paper\",\n",
    "                x0=0, y0=0, x1=1, y1=1,\n",
    "                line=dict(color=\"black\", width=2)\n",
    "            )\n",
    "        ],\n",
    "        # Optionally, set the template and margins.\n",
    "        template=\"plotly_white\",\n",
    "        margin=dict(l=50, r=50, t=50, b=50)\n",
    "    )\n",
    "        \n",
    "    figw = FigureWidget(fig)\n",
    "\n",
    "    # --- GLOBAL STORAGE FOR SELECTIONS ---\n",
    "    global_persisted_indices_spoc = set()\n",
    "\n",
    "    def handle_selection(trace, points, selector):\n",
    "        global global_persisted_indices_spoc\n",
    "        global_persisted_indices_spoc.update(points.point_inds)\n",
    "        if not global_persisted_indices_spoc:\n",
    "            print(\"No points selected.\")\n",
    "            return\n",
    "        print(\"Accumulated selected indices:\", global_persisted_indices_spoc)\n",
    "        selected_df = merged_df.iloc[list(global_persisted_indices_spoc)]\n",
    "        \n",
    "        # Example label: extract a short uniprot name from 'NAME' or just show the \"index\"\n",
    "        def process_name(name_str):\n",
    "            try:\n",
    "                parts = name_str.split(\"_vs_\")\n",
    "                if len(parts) < 2:\n",
    "                    return name_str\n",
    "                # E.g. \"sp-Q13889-TF2H3_HUMAN\"\n",
    "                hit = parts[1]\n",
    "                hit_parts = hit.split(\"-\")\n",
    "                if len(hit_parts) < 3:\n",
    "                    return hit\n",
    "                return hit_parts[2].split(\"_\")[0]\n",
    "            except:\n",
    "                return name_str\n",
    "        \n",
    "        labels = selected_df[\"NAME\"].apply(process_name)\n",
    "        \n",
    "        # Check if we already have a \"Persistent Labels\" trace\n",
    "        persistent_trace = None\n",
    "        for t in figw.data:\n",
    "            if t.name == \"Persistent Labels\":\n",
    "                persistent_trace = t\n",
    "                break\n",
    "        \n",
    "        if persistent_trace is None:\n",
    "            figw.add_scatter(\n",
    "                x=selected_df[\"scaled_PEAKavg\"],\n",
    "                y=selected_df[\"IPTMavg\"],\n",
    "                mode=\"text\",\n",
    "                text=labels,\n",
    "                textposition=\"top center\",\n",
    "                name=\"Labels (double click to hide)\",\n",
    "                hoverinfo=\"skip\",\n",
    "                textfont=dict(color=\"black\", size=8)\n",
    "            )\n",
    "        else:\n",
    "            persistent_trace.x = selected_df[\"scaled_PEAKavg\"]\n",
    "            persistent_trace.y = selected_df[\"IPTMavg\"]\n",
    "            persistent_trace.text = labels\n",
    "\n",
    "    # Attach selection callback\n",
    "    for trace in figw.data:\n",
    "        trace.on_selection(handle_selection)\n",
    "\n",
    "    # --- STANDARD SEARCH (by substring) WIDGETS ---\n",
    "    search_input_spoc = widgets.Text(\n",
    "        value=\"\",\n",
    "        placeholder=\"Enter partial name to search\",\n",
    "        description=\"Search NAME:\",\n",
    "        style={'description_width': '120px'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    search_button_spoc = widgets.Button(\n",
    "        description=\"Search\",\n",
    "        tooltip=\"Search partial matches\",\n",
    "        button_style=\"primary\"\n",
    "    )\n",
    "    clear_search_button_spoc = widgets.Button(\n",
    "        description=\"Clear Search\",\n",
    "        tooltip=\"Remove search highlights\",\n",
    "        button_style=\"warning\"\n",
    "    )\n",
    "\n",
    "    def on_search_button_click_spoc(b):\n",
    "        query = search_input_spoc.value.strip()\n",
    "        if not query:\n",
    "            print(\"Please enter a search query.\")\n",
    "            return\n",
    "        mask = merged_df[\"NAME\"].str.contains(query, case=False, na=False)\n",
    "        matched = merged_df[mask]\n",
    "        if matched.empty:\n",
    "            print(\"No matches found.\")\n",
    "            return\n",
    "        \n",
    "        # Add highlight scatter\n",
    "        figw.add_scatter(\n",
    "            x=matched[\"scaled_PEAKavg\"],\n",
    "            y=matched[\"IPTMavg\"],\n",
    "            mode=\"markers+text\",\n",
    "            marker=dict(symbol=\"circle-open\", size=8, line=dict(width=2, color=\"red\")),\n",
    "            text=[query]*len(matched),\n",
    "            textposition=\"top center\",\n",
    "            name=\"Search Highlight\",\n",
    "            hoverinfo=\"skip\"\n",
    "        )\n",
    "        print(f\"Found {len(matched)} match(es). Highlights added.\")\n",
    "\n",
    "    def on_clear_search_button_click_spoc(b):\n",
    "        indices_to_remove = [i for i, t in enumerate(figw.data) if t.name == \"Search Highlight\"]\n",
    "        if not indices_to_remove:\n",
    "            print(\"No search highlights to clear.\")\n",
    "            return\n",
    "        for idx in sorted(indices_to_remove, reverse=True):\n",
    "            figw.data = figw.data[:idx] + figw.data[idx+1:]\n",
    "        print(\"Search highlights cleared.\")\n",
    "    \n",
    "    search_button_spoc.on_click(on_search_button_click_spoc)\n",
    "    clear_search_button_spoc.on_click(on_clear_search_button_click_spoc)\n",
    "\n",
    "    # --- NEW MULTI-GROUP INDEX + COLOR HIGHLIGHT ---\n",
    "    # Example input: (1,5,12,19=green) (2,9,200=red)\n",
    "    group_highlight_input_spoc = widgets.Text(\n",
    "        ##TRICK THE COPY PASTE BIUG HERE!!###\n",
    "        value=\"(245,22,250,743,690,261,233,229,479,464,107,1,203,660,659,648,363,462,474,475,492,271,192,97=green) (33=grey) (591,425,761,771,286,385,233,479,464,203,660,659,648,462,474,492,192,508,181,190,64,579,40,708,364,416,35,151=red) (436,117,630,573,3,60,687=black)(400,411,423=blue)\",\n",
    "        placeholder=\"(192,97=green) (35,151=red)\",\n",
    "        description=\"Multi-Groups:\",\n",
    "        style={'description_width': '100px'},\n",
    "        layout={'width': '600px'}\n",
    "    )\n",
    "    group_highlight_button_spoc = widgets.Button(\n",
    "        description=\"Highlight Groups\",\n",
    "        tooltip=\"Highlight multiple index groups, each with a color\",\n",
    "        button_style=\"info\"\n",
    "    )\n",
    "\n",
    "    def on_group_highlight_button_click_spoc(b):\n",
    "        \"\"\"\n",
    "        Example input: (743=green) (385,23,151=red) (20,21,423=blue)\n",
    "        Each group is parsed, and for each group we use the name value for labeling.\n",
    "        \"\"\"\n",
    "        input_str = group_highlight_input_spoc.value.strip()\n",
    "        if not input_str:\n",
    "            print(\"No group spec given. Format: (1,5,12=red) (2,9=green)\")\n",
    "            return\n",
    "\n",
    "        # Split by closing parenthesis, filtering out empties.\n",
    "        group_specs = [chunk.strip() for chunk in input_str.split(\")\") if chunk.strip()]\n",
    "\n",
    "        for spec in group_specs:\n",
    "            # Remove any leading \"(\" if present.\n",
    "            if spec.startswith(\"(\"):\n",
    "                spec = spec[1:].strip()\n",
    "\n",
    "            # Split on \"=\" to separate indices from the color.\n",
    "            if \"=\" in spec:\n",
    "                left_part, color_part = spec.split(\"=\", 1)\n",
    "                indices_str = left_part.strip()\n",
    "                color_str = color_part.strip()\n",
    "            else:\n",
    "                indices_str = spec\n",
    "                color_str = \"red\"  # default\n",
    "\n",
    "            # Split indices (comma-separated).\n",
    "            idx_list = [x.strip() for x in indices_str.split(\",\") if x.strip()]\n",
    "            if not idx_list:\n",
    "                print(f\"No valid indices found in '{spec}'\")\n",
    "                continue\n",
    "\n",
    "            # Find all matching rows in merged_df.\n",
    "            matched = merged_df[merged_df[\"index\"].isin(idx_list)]\n",
    "            if matched.empty:\n",
    "                print(f\"No match for indices {idx_list}\")\n",
    "                continue\n",
    "\n",
    "            # Use the name column for labeling.\n",
    "            group_label = matched[\"name\"]\n",
    "\n",
    "            # Add one scatter trace for the group.\n",
    "            figw.add_scatter(\n",
    "                x=matched[\"scaled_PEAKavg\"],\n",
    "                y=matched[\"IPTMavg\"],\n",
    "                mode=\"markers+text\",\n",
    "                showlegend=False,             # <--- Hide from legend\n",
    "                marker=dict(symbol=\"circle\", color=color_str, size=5),\n",
    "                text=group_label,\n",
    "                textposition=\"top center\",\n",
    "                name=f\"Highlight\",\n",
    "                hoverinfo=\"skip\"\n",
    "            )\n",
    "            print(f\"Highlighted indices {idx_list} in color '{color_str}'\")\n",
    "\n",
    "        print(\"Group highlight done.\")\n",
    "\n",
    "    group_highlight_button_spoc.on_click(on_group_highlight_button_click_spoc)\n",
    "\n",
    "    # --- CLEAR LABELS & SAVE PLOT ---\n",
    "    clear_labels_button_spoc = widgets.Button(\n",
    "        description=\"Clear Labels\",\n",
    "        button_style=\"warning\"\n",
    "    )\n",
    "    def on_clear_labels_click_spoc(b):\n",
    "        global_persisted_indices_spoc\n",
    "        global_persisted_indices_spoc.clear()\n",
    "\n",
    "        # Remove the \"Persistent Labels\" or highlight traces if needed\n",
    "        names_to_remove = [\"Persistent Labels\"]\n",
    "        # Also remove any highlight traces we might want to clear\n",
    "        # If you only want to remove the \"Persistent Labels\", \n",
    "        # leave out highlight traces from the list above.\n",
    "        indices_to_remove = [\n",
    "            i for i, t in enumerate(figw.data) \n",
    "            if t.name in names_to_remove or t.name.startswith(\"Highlight \")\n",
    "        ]\n",
    "        for idx in sorted(indices_to_remove, reverse=True):\n",
    "            figw.data = figw.data[:idx] + figw.data[idx+1:]\n",
    "        print(\"Persistent labels and highlight traces cleared.\")\n",
    "\n",
    "    clear_labels_button_spoc.on_click(on_clear_labels_click_spoc)\n",
    "\n",
    "    save_plot_button_spoc = widgets.Button(\n",
    "        description=\"Save Plot (HTML & PDF)\",\n",
    "        tooltip=\"Save the current plot\",\n",
    "        button_style=\"info\"\n",
    "    )\n",
    "\n",
    "\n",
    "    file_name_widget_spoc = widgets.Text(\n",
    "        value=\"selected_data.csv\",\n",
    "        placeholder=\"Enter file name\",\n",
    "        description=\"Save CSV as:\",\n",
    "        disabled=False\n",
    "    )\n",
    "    save_data_button_spoc = widgets.Button(\n",
    "        description=\"Save Data\",\n",
    "        button_style=\"success\"\n",
    "    )\n",
    "    save_data_output_spoc = widgets.Output()\n",
    "    \n",
    "    \n",
    "    import datetime\n",
    "\n",
    "    custom_suffix_save = widgets.Text(\n",
    "        value=\"\",\n",
    "        placeholder=\"Add file name suffix\",\n",
    "        description=\"Filename Suffix:\",\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    \n",
    "    def on_save_plot_click_spoc(b):\n",
    "        try:\n",
    "            # Retrieve custom suffix from widget and current timestamp.\n",
    "            suffix = custom_suffix_save.value.strip()\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            if suffix:\n",
    "                suffix_str = f\"_{suffix}_{timestamp}\"\n",
    "            else:\n",
    "                suffix_str = f\"_{timestamp}\"\n",
    "            \n",
    "            # Build file paths with the custom suffix and timestamp.\n",
    "            html_filename = f\"spoc_bubble_chart{suffix_str}.html\"\n",
    "            pdf_filename = f\"spoc_bubble_chart{suffix_str}.pdf\"\n",
    "            html_path = os.path.join(output_dir, html_filename)\n",
    "            pdf_path = os.path.join(output_dir, pdf_filename)\n",
    "            \n",
    "            # Save the figure.\n",
    "            figw.write_html(html_path)\n",
    "            figw.write_image(pdf_path, format=\"pdf\")\n",
    "            print(f\"Plot saved:\\n  HTML: {html_path}\\n  PDF: {pdf_path}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error saving plot:\", e)\n",
    "\n",
    "    save_plot_button_spoc.on_click(on_save_plot_click_spoc)\n",
    "\n",
    "    # --- DISPLAY ---\n",
    "    instructions_text_spoc = \"\"\"\n",
    "    **SPOC-Based Plot Instructions:**\n",
    "    1. **Use Lasso/Box select to pick points and persist labels**.\n",
    "    2. (Optional) Search by partial `NAME` using the first box, then clear highlights if needed.\n",
    "    3. **Highlight by index** (the digits before the underscore) using the second box, \n",
    "       e.g. (1,5,12,19=green) (2,9,200=red) (20=blue)\n",
    "    4. Clear persistent labels and/or highlight traces if needed.\n",
    "    5. Save the plot (HTML & PDF) or selected data (CSV).\n",
    "    \"\"\"\n",
    "    display(Markdown(instructions_text_spoc))\n",
    "    display(widgets.HBox([search_input_spoc, search_button_spoc, clear_search_button_spoc]))\n",
    "    \n",
    "    # The new multi-index highlight input\n",
    "    # Now just display the new widgets:\n",
    "    display(widgets.HBox([group_highlight_input_spoc, group_highlight_button_spoc]))\n",
    "    display(widgets.HBox([clear_labels_button_spoc]))\n",
    "\n",
    "    display(widgets.HBox([custom_suffix_save, save_plot_button_spoc]))\n",
    "\n",
    "\n",
    "    display(figw)\n",
    "    display(widgets.HBox([file_name_widget_spoc, save_data_button_spoc]))\n",
    "    display(save_data_output_spoc)\n",
    "\n",
    "else:\n",
    "    print(\"Skipping SPOC-based bubble chart...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with external data\n",
    "TO tricky the copy apste button, search the code for \"##TRICK THE COPY PASTE BIUG HERE!!###\" and enter your hiohglits there!\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MS data with shape: (1681, 5)\n",
      "Merged DataFrame shape after merging MS data: (831, 71)\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: MERGE MS DATA ===\n",
    "ms_file_path = \"/Volumes/plaschka/shared/data/mass-spec/MS_analysis/analysis/MV_RPB3_FLAG_pretty/exports/merged_data_20250319_182512_with_nuc_vs_chrom_with_fraction_dependency.csv\"\n",
    "\n",
    "#df_ms = pd.read_csv(ms_file_path, sep=\",\")\n",
    "df_ms = pd.read_csv(ms_file_path)\n",
    "\n",
    "print(\"Loaded MS data with shape:\", df_ms.shape)\n",
    "\n",
    "#def extract_target_uniprot(name_str):\n",
    "#    try:\n",
    "#        parts = name_str.split(\"_vs_\")\n",
    "#        if len(parts) < 2:\n",
    "#            return None\n",
    "#        target = parts[1]  # e.g., \"sp-Q9Y3X0-CCDC9_HUMAN\"\n",
    "#        target_parts = target.split(\"-\")\n",
    "#        if len(target_parts) < 2:\n",
    "#            return None\n",
    "#        return target_parts[1]  # e.g. \"Q9Y3X0\"\n",
    "#    except Exception:\n",
    "#        return None\n",
    "#\n",
    "## Create a new column in merged_df with the target uniprot IDs.\n",
    "#merged_df[\"target_uniprot\"] = merged_df[\"NAME\"].apply(extract_target_uniprot)\n",
    "#print(\"Extracted target_uniprot in merged_df.\")\n",
    "\n",
    "# Merge the MS data with merged_df on \"Accession\" from MS data and \"target_uniprot\" in merged_df.\n",
    "merged_df = pd.merge(merged_df, df_ms, left_on=\"target_uniprot_id\", right_on=\"Accession\", how=\"left\")\n",
    "print(\"Merged DataFrame shape after merging MS data:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose columns for mapping color, size and opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing config from config.json: {'color_column': 'FractionDependent', 'size_column': 'DNaseI digest chromatin FLAG-mCh_RPB3 vs DNaseI digest chromatin WT', 'opacity_column': 'IPTM_max', 'color_transform': 'None', 'size_transform': 'None', 'opacity_transform': 'None'}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Select columns for mapping color, size and transparency and their transformations:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e4aa9cc5274c3bbf2194a9d2364b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Color Col:', index=46, layout=Layout(width='220px'), options=('IPTMavg', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b839794e9034c288378ce1a6c6074d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Color Transform:', layout=Layout(width='220px'), options=('None', 'log2',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefb27dce6f5422a807d48fedc07b9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Config', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjust columns/transforms as desired, then click 'Save Config'. Next, run Cell 2.\n"
     ]
    }
   ],
   "source": [
    "# === CELL 1: Column & Transform Selection, Save to JSON Config ===\n",
    "import os\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "config_file = \"config.json\"\n",
    "\n",
    "numeric_cols = merged_df.select_dtypes(include=[float, int]).columns.tolist()\n",
    "transform_options = [\"None\", \"log2\", \"log10\"]\n",
    "\n",
    "if os.path.exists(config_file):\n",
    "    with open(config_file, \"r\") as f:\n",
    "        prev_cfg = json.load(f)\n",
    "    print(f\"Loaded existing config from {config_file}: {prev_cfg}\")\n",
    "else:\n",
    "    prev_cfg = {}\n",
    "    print(\"No config file found; using empty defaults.\")\n",
    "\n",
    "def dict_get(d, key, fallback):\n",
    "    return d[key] if key in d else fallback\n",
    "\n",
    "color_selector = widgets.Dropdown(\n",
    "    options=numeric_cols,\n",
    "    value=dict_get(prev_cfg, \"color_column\", \"scaled_PEAKavg\"),\n",
    "    description=\"Color Col:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "size_selector = widgets.Dropdown(\n",
    "    options=numeric_cols,\n",
    "    value=dict_get(prev_cfg, \"size_column\", \"spoc_score\"),\n",
    "    description=\"Size Col:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "opacity_selector = widgets.Dropdown(\n",
    "    options=numeric_cols,\n",
    "    value=dict_get(prev_cfg, \"opacity_column\", \"spoc_score\"),\n",
    "    description=\"Opacity Col:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "\n",
    "color_transform_selector = widgets.Dropdown(\n",
    "    options=transform_options,\n",
    "    value=dict_get(prev_cfg, \"color_transform\", \"None\"),\n",
    "    description=\"Color Transform:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "size_transform_selector = widgets.Dropdown(\n",
    "    options=transform_options,\n",
    "    value=dict_get(prev_cfg, \"size_transform\", \"None\"),\n",
    "    description=\"Size Transform:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "opacity_transform_selector = widgets.Dropdown(\n",
    "    options=transform_options,\n",
    "    value=dict_get(prev_cfg, \"opacity_transform\", \"None\"),\n",
    "    description=\"Opac Transform:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "\n",
    "display(Markdown(\"### Select columns for mapping color, size and transparency and their transformations:\"))\n",
    "display(widgets.HBox([color_selector, size_selector, opacity_selector]))\n",
    "display(widgets.HBox([\n",
    "    color_transform_selector, size_transform_selector, opacity_transform_selector\n",
    "]))\n",
    "\n",
    "def on_save_config(b):\n",
    "    cfg = {\n",
    "        \"color_column\": color_selector.value,\n",
    "        \"size_column\": size_selector.value,\n",
    "        \"opacity_column\": opacity_selector.value,\n",
    "        \"color_transform\": color_transform_selector.value,\n",
    "        \"size_transform\": size_transform_selector.value,\n",
    "        \"opacity_transform\": opacity_transform_selector.value\n",
    "    }\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(cfg, f)\n",
    "    print(\"[Cell1] Configuration saved to\", config_file, \":\", cfg)\n",
    "\n",
    "save_button = widgets.Button(description=\"Save Config\", button_style=\"success\")\n",
    "save_button.on_click(on_save_config)\n",
    "display(save_button)\n",
    "\n",
    "print(\"Adjust columns/transforms as desired, then click 'Save Config'. Next, run Cell 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional config file overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config file overwrite\n",
    "#Load a different config file if required\n",
    "config_file = \"config.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select dynamic range and generate plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Click the load & Apply config button first!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8bec04f3044d12b3dc16352dbed9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Load & Apply Config', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd76606195d4ad488388fc6a345c027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Adjust Ranges & Color Scale"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19256354950740eea3d95625e9930223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Color Scale:', layout=Layout(width='220px'), options=('viridis', 'magma',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Color Range**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1dcbcd5be3463598214c4104028d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=0.0, description='Color Min:', layout=Layout(width='200px')), FloatText(value=0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Size Range**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c2727ea81c4f459a546387bf6b1aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=0.0, description='Size Min:', layout=Layout(width='200px')), FloatText(value=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Opacity Range** (Decrease upper value to increase visibility)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffa36b329b6475c9930634608f25adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=0.0, description='Opac Min:', layout=Layout(width='200px')), FloatText(value=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Note**: You can save the path of the config json file in Cell 1 to load later."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 4) Generate Plot with chosen ranges"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc2cd5032ac4dbca26e3e0507c6b0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Generate Plot', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Searching & Group Highlight"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Enter multiple semi-colon seperated values to retrieve partial matches in the search 'NAME box'.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51b921dbc8d4043b8a82b39a90c2726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Search NAME:', layout=Layout(width='300px'), placeholder='Enter par…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Enter multiple comma seperated index value and the color you want to use for highlighing 'NAME box'.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab57383dd6a4aff9334cc8efb4886a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='(245,22,250,743,690,261,233,229,479,464,107,1,203,660,659,648,363,462,474,475,492,2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554b9507175949d28db29d1a7176d64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Save Figure & Settings & Export Selected Points to CSV"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ce36ae0d8140f49880968623bb98c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Filename Suffix:', layout=Layout(width='300px'), placeholder='File …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Output(), Output()]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0b5ebbe91b43f9894e94a5a3362e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8d5a2ef3c445cc9965ce2546b84cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='selected_data_dynamic.csv', description='Save CSV as:', layout=Layout(width='300px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === CELL 2: Load & Apply + Ranges + Color Scale => Generate Advanced Plot ===\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import plotly.express as px\n",
    "from plotly.graph_objs import FigureWidget\n",
    "import datetime\n",
    "\n",
    "###############################################################################\n",
    "# 1) Transform function: zero -> 5% quantile, optional log\n",
    "###############################################################################\n",
    "def apply_transform_with_5pct(series, transform_kind=\"None\"):\n",
    "    s = series.fillna(0).copy()\n",
    "    pos_mask = (s > 0)\n",
    "    if pos_mask.any():\n",
    "        q5 = np.quantile(s[pos_mask], 0.05)\n",
    "        if q5 <= 0:\n",
    "            q5 = 1e-6\n",
    "    else:\n",
    "        q5 = 1e-6\n",
    "    s[s==0] = q5\n",
    "    if transform_kind == \"None\":\n",
    "        return s\n",
    "    if (s < 0).any():\n",
    "        raise ValueError(f\"Negative data found for {transform_kind} transform.\")\n",
    "    if transform_kind == \"log2\":\n",
    "        return np.log2(s)\n",
    "    elif transform_kind == \"log10\":\n",
    "        return np.log10(s)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid transform option\")\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2) Load & Apply => create *processed columns => display default min/max\n",
    "###############################################################################\n",
    "load_output = widgets.Output()\n",
    "color_min_box = widgets.FloatText(description=\"Color Min:\", layout={'width': '200px'})\n",
    "color_max_box = widgets.FloatText(description=\"Color Max:\", layout={'width': '200px'})\n",
    "size_min_box  = widgets.FloatText(description=\"Size Min:\", layout={'width': '200px'})\n",
    "size_max_box  = widgets.FloatText(description=\"Size Max:\", layout={'width': '200px'})\n",
    "opac_min_box  = widgets.FloatText(description=\"Opac Min:\", layout={'width': '200px'})\n",
    "opac_max_box  = widgets.FloatText(description=\"Opac Max:\", layout={'width': '200px'})\n",
    "\n",
    "# Let user pick color scale & reverse\n",
    "color_scales = [\"viridis\",\"magma\",\"inferno\",\"plasma\",\"Blues\",\"Reds\",\"RdBu\",\"cividis\",\"PuOr\"]\n",
    "color_scale_selector = widgets.Dropdown(\n",
    "    options=color_scales,\n",
    "    value=\"viridis\",\n",
    "    description=\"Color Scale:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "reverse_scale_checkbox = widgets.Checkbox(value=False, description=\"Reverse Scale\")\n",
    "\n",
    "# Store the chosen columns/transforms in these globals:\n",
    "global_color_col = None\n",
    "global_size_col = None\n",
    "global_opacity_col = None\n",
    "global_color_xform = None\n",
    "global_size_xform = None\n",
    "global_opacity_xform = None\n",
    "\n",
    "def on_load_apply_config(b):\n",
    "    global global_color_col, global_size_col, global_opacity_col\n",
    "    global global_color_xform, global_size_xform, global_opacity_xform\n",
    "    with load_output:\n",
    "        load_output.clear_output()\n",
    "        try:\n",
    "            # 1) read config\n",
    "            config_file = \"config.json\"\n",
    "            if not os.path.exists(config_file):\n",
    "                print(\"No config.json found. Please run Cell 1 and save config.\")\n",
    "                return\n",
    "            with open(config_file,\"r\") as f:\n",
    "                final_cfg = json.load(f)\n",
    "\n",
    "            # 2) Store them in the global variables\n",
    "            global_color_col   = final_cfg.get(\"color_column\",\"scaled_PEAKavg\")\n",
    "            global_size_col    = final_cfg.get(\"size_column\",\"spoc_score\")\n",
    "            global_opacity_col = final_cfg.get(\"opacity_column\",\"spoc_score\")\n",
    "            global_color_xform = final_cfg.get(\"color_transform\",\"None\")\n",
    "            global_size_xform  = final_cfg.get(\"size_transform\",\"None\")\n",
    "            global_opacity_xform = final_cfg.get(\"opacity_transform\",\"None\")\n",
    "\n",
    "            # 3) transform the columns in merged_df\n",
    "            merged_df[\"color_processed\"]   = apply_transform_with_5pct(merged_df[global_color_col],   global_color_xform)\n",
    "            merged_df[\"size_processed\"]    = apply_transform_with_5pct(merged_df[global_size_col],    global_size_xform)\n",
    "            merged_df[\"opacity_processed\"] = apply_transform_with_5pct(merged_df[global_opacity_col], global_opacity_xform)\n",
    "\n",
    "            # Show min/max\n",
    "            cmin, cmax = merged_df[\"color_processed\"].min(), merged_df[\"color_processed\"].max()\n",
    "            smin, smax = merged_df[\"size_processed\"].min(),  merged_df[\"size_processed\"].max()\n",
    "            omin, omax = merged_df[\"opacity_processed\"].min(), merged_df[\"opacity_processed\"].max()\n",
    "\n",
    "            color_min_box.value, color_max_box.value = cmin, cmax\n",
    "            size_min_box.value, size_max_box.value   = smin, smax\n",
    "            opac_min_box.value, opac_max_box.value   = omin, omax\n",
    "\n",
    "            # 4) if config had color_scale & reverse, load them\n",
    "            cscale = final_cfg.get(\"color_scale\",\"viridis\")\n",
    "            color_scale_selector.value = cscale\n",
    "            rev = final_cfg.get(\"reverse_scale\",False)\n",
    "            reverse_scale_checkbox.value = rev\n",
    "            \n",
    "            print(\"[Load] Config:\", final_cfg)\n",
    "            print(f\" color_processed => [{cmin:.3f}..{cmax:.3f}]\")\n",
    "            print(f\" size_processed => [{smin:.3f}..{smax:.3f}]\")\n",
    "            print(f\" opacity_processed => [{omin:.3f}..{omax:.3f}]\")\n",
    "        except ValueError as e:\n",
    "            print(\"[Load Error]\", e)\n",
    "\n",
    "load_button = widgets.Button(description=\"Load & Apply Config\", button_style=\"primary\")\n",
    "load_button.on_click(on_load_apply_config)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3) Generate Plot (with advanced features)\n",
    "###############################################################################\n",
    "plot_output = widgets.Output()\n",
    "global_persisted_indices_dynamic = set()  # for selection\n",
    "\n",
    "def on_generate_plot_click(b):\n",
    "    with plot_output:\n",
    "        plot_output.clear_output()\n",
    "        \n",
    "        # 1) read range values from the widgets\n",
    "        cmin = color_min_box.value\n",
    "        cmax = color_max_box.value\n",
    "        smin = size_min_box.value\n",
    "        smax = size_max_box.value\n",
    "        omin = opac_min_box.value\n",
    "        omax = opac_max_box.value\n",
    "\n",
    "        # color scale\n",
    "        chosen_cscale = color_scale_selector.value\n",
    "        if reverse_scale_checkbox.value:\n",
    "            chosen_cscale += \"_r\"\n",
    "\n",
    "        # 2) clamp color & size\n",
    "        def clamp(arr, low, high):\n",
    "            return arr.clip(low,high)\n",
    "\n",
    "        merged_df[\"color_clamped\"] = clamp(merged_df[\"color_processed\"], cmin, cmax)\n",
    "        merged_df[\"size_clamped\"]  = clamp(merged_df[\"size_processed\"], smin, smax)\n",
    "\n",
    "        # 3) map opacity => [0..1]\n",
    "        arr_op = merged_df[\"opacity_processed\"].values\n",
    "        if np.isclose(omax, omin):\n",
    "            arr_map = np.full_like(arr_op, 0.5)\n",
    "        else:\n",
    "            arr_map = (arr_op - omin)/(omax - omin)\n",
    "        arr_map = np.clip(arr_map, 0, 1)\n",
    "\n",
    "        # 4) build figure\n",
    "        fig = px.scatter(\n",
    "            merged_df,\n",
    "            x=\"scaled_PEAKavg\",\n",
    "            y=\"IPTMavg\",\n",
    "            color=\"color_clamped\",\n",
    "            size=\"size_clamped\",\n",
    "            hover_data=[\"NAME\",\"color_processed\",\"size_processed\",\"opacity_processed\",\"hover_text\"],\n",
    "            color_continuous_scale=chosen_cscale,\n",
    "            range_color=[cmin, cmax],\n",
    "            labels={\"color_clamped\": \"\"},  # blank legend label\n",
    "            title=\"Alphafold PEAKavg vs. IPTMavg plot\"\n",
    "        )\n",
    "        \n",
    "        # 5) example text annotation describing the mappings\n",
    "        mapping_text = (\n",
    "            f\"Color mapped to {color_selector.value} (transform: {color_transform_selector.value})<br>\"\n",
    "            f\"Size mapped to {size_selector.value} (transform: {size_transform_selector.value})<br>\"\n",
    "            f\"Opacity mapped to {opacity_selector.value} (transform: {opacity_transform_selector.value})\"\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=0,\n",
    "            y=0.92,\n",
    "            xanchor=\"left\",\n",
    "            yanchor=\"bottom\",\n",
    "            showarrow=False,\n",
    "            text=mapping_text,\n",
    "            font=dict(size=12, color=\"black\")\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            clickmode=\"event+select\",\n",
    "            autosize=False,\n",
    "            width=800,   # pick a fixed width\n",
    "            height=600,\n",
    "            legend=dict(\n",
    "                x=0.05,       # shift legend to the right of the main plot\n",
    "                xanchor=\"left\",\n",
    "                y=1.0,\n",
    "                yanchor=\"top\"\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                showgrid=False, \n",
    "                showline=True, \n",
    "                linewidth=2, \n",
    "                linecolor='black',\n",
    "                range=[0,1]  # Force x-axis range\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                showgrid=False, \n",
    "                showline=True, \n",
    "                linewidth=2, \n",
    "                linecolor='black',\n",
    "                range=[0,1]  # Force y-axis range\n",
    "            ),\n",
    "            shapes=[\n",
    "                # Outer border rectangle (in paper coordinates)\n",
    "                dict(\n",
    "                    type=\"rect\",\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x0=0, y0=0, x1=1, y1=1,\n",
    "                    line=dict(color=\"black\", width=2)\n",
    "                ),\n",
    "                # Horizontal line at y=0.5 (in axis coordinates)\n",
    "                dict(\n",
    "                    type=\"line\",\n",
    "                    xref=\"x\", yref=\"y\",\n",
    "                    x0=0, x1=1, y0=0.5, y1=0.5,\n",
    "                    line=dict(color=\"black\", width=2, dash=\"dash\")\n",
    "                ),\n",
    "                # Vertical line at x=0.75 (in axis coordinates)\n",
    "                dict(\n",
    "                    type=\"line\",\n",
    "                    xref=\"x\", yref=\"y\",\n",
    "                    x0=0.75, x1=0.75, y0=0, y1=1,\n",
    "                    line=dict(color=\"black\", width=2, dash=\"dash\")\n",
    "                )\n",
    "            ],\n",
    "            template=\"plotly_white\",\n",
    "            margin=dict(l=50, r=50, t=50, b=50)\n",
    ")\n",
    "        # 6) define selection callback for lasso/box\n",
    "        def handle_selection(trace, points, selector):\n",
    "            global global_persisted_indices_dynamic\n",
    "            global_persisted_indices_dynamic.update(points.point_inds)\n",
    "            if not global_persisted_indices_dynamic:\n",
    "                print(\"[Plot] No points selected.\")\n",
    "                return\n",
    "            print(\"[Plot] Accumulated indices:\", global_persisted_indices_dynamic)\n",
    "            sel_df = merged_df.iloc[list(global_persisted_indices_dynamic)]\n",
    "\n",
    "            labels = sel_df[\"name\"]  # or another label\n",
    "\n",
    "            # see if \"Persistent Labels\" trace exists\n",
    "            persist_tr = None\n",
    "            for t in figw.data:\n",
    "                if t.name == \"Persistent Labels\":\n",
    "                    persist_tr = t\n",
    "                    break\n",
    "            if persist_tr is None:\n",
    "                figw.add_scatter(\n",
    "                    x=sel_df[\"scaled_PEAKavg\"],\n",
    "                    y=sel_df[\"IPTMavg\"],\n",
    "                    mode=\"text\",\n",
    "                    text=labels,\n",
    "                    textposition=\"top center\",\n",
    "                    name=\"Persistent Labels\",\n",
    "                    showlegend=False,             # <--- Hide from legend\n",
    "                    hoverinfo=\"skip\",\n",
    "                    textfont=dict(color=\"black\", size=8)\n",
    "                )\n",
    "            else:\n",
    "                persist_tr.x = sel_df[\"scaled_PEAKavg\"]\n",
    "                persist_tr.y = sel_df[\"IPTMavg\"]\n",
    "                persist_tr.text = labels\n",
    "        \n",
    "        \n",
    "        # display final figure\n",
    "        display(Markdown(\"### Select the lasso tool and click to label a single point or lasso-select to label a range. Double click on the backgorund to restore transparency settings\"))\n",
    "\n",
    "\n",
    "        figw = FigureWidget(fig)\n",
    "        display(figw)\n",
    "\n",
    "        # 5) attach click callback\n",
    "        for tr in figw.data:\n",
    "            tr.on_selection(handle_selection)  # already there\n",
    "            tr.on_click(handle_click)         # new: attach the click callback\n",
    " \n",
    "        # store for searches, highlights, saves\n",
    "        global global_figw_for_search\n",
    "        global_figw_for_search = figw\n",
    "\n",
    "        # apply per-point marker opacity\n",
    "        for trace in figw.data:\n",
    "            trace.marker.opacity = arr_map\n",
    "            trace.marker.line = dict(width=1, color=\"black\")\n",
    "            \n",
    "        \n",
    "\n",
    "generate_plot_button = widgets.Button(\n",
    "    description=\"Generate Plot\",\n",
    "    button_style=\"info\"\n",
    ")\n",
    "generate_plot_button.on_click(on_generate_plot_click)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# SAVE FIGURE & SETTINGS BUTTON\n",
    "###############################################################################\n",
    "save_figure_button = widgets.Button(description=\"Save Figure & Settings\", button_style=\"success\")\n",
    "save_figure_suffix = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"File name suffix\",\n",
    "    description=\"Filename Suffix:\",\n",
    "    layout={'width': '300px'}\n",
    ")\n",
    "save_figure_output = widgets.Output()\n",
    "\n",
    "def on_save_figure_click(b):\n",
    "    with save_figure_output:\n",
    "        save_figure_output.clear_output()\n",
    "        global global_figw_for_search\n",
    "        if global_figw_for_search is None:\n",
    "            print(\"No figure to save! Please 'Generate Plot' first.\")\n",
    "            return\n",
    "        \n",
    "        suffix_input = save_figure_suffix.value.strip()\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if suffix_input:\n",
    "            suffix_str = f\"_{suffix_input}_{timestamp}\"\n",
    "        else:\n",
    "            suffix_str = f\"_{timestamp}\"\n",
    "\n",
    "        # Build final file paths\n",
    "        html_name = os.path.join(output_dir, f\"AF_plot_{suffix_str}.html\")\n",
    "        pdf_name  = os.path.join(output_dir, f\"AF_plot_{suffix_str}.pdf\")\n",
    "        json_name = os.path.join(output_dir, f\"AF_plot_{suffix_str}_settings.json\")\n",
    "\n",
    "        # Gather user settings from global variables\n",
    "        try:\n",
    "            ccol   = global_color_col\n",
    "            scol   = global_size_col\n",
    "            ocol   = global_opacity_col\n",
    "            cx     = global_color_xform\n",
    "            sx     = global_size_xform\n",
    "            ox     = global_opacity_xform\n",
    "        except NameError:\n",
    "            print(\"No config loaded, can't save settings!\")\n",
    "            return\n",
    "        \n",
    "        # Convert widget values to native Python types\n",
    "        cmin = float(color_min_box.value)\n",
    "        cmax = float(color_max_box.value)\n",
    "        smin = float(size_min_box.value)\n",
    "        smax = float(size_max_box.value)\n",
    "        omin = float(opac_min_box.value)\n",
    "        omax = float(opac_max_box.value)\n",
    "        chosen_scale = color_scale_selector.value\n",
    "        rev_scale = bool(reverse_scale_checkbox.value)\n",
    "\n",
    "        final_settings = {\n",
    "            \"color_column\": ccol,\n",
    "            \"size_column\": scol,\n",
    "            \"opacity_column\": ocol,\n",
    "            \"color_transform\": cx,\n",
    "            \"size_transform\": sx,\n",
    "            \"opacity_transform\": ox,\n",
    "            \"color_min\": cmin,\n",
    "            \"color_max\": cmax,\n",
    "            \"size_min\": smin,\n",
    "            \"size_max\": smax,\n",
    "            \"opacity_min\": omin,\n",
    "            \"opacity_max\": omax,\n",
    "            \"color_scale\": chosen_scale,\n",
    "            \"reverse_scale\": rev_scale\n",
    "        }\n",
    "\n",
    "        # Save figure to HTML & PDF\n",
    "        try:\n",
    "            global_figw_for_search.write_html(html_name)\n",
    "            global_figw_for_search.write_image(pdf_name, format=\"pdf\")\n",
    "        except Exception as e:\n",
    "            print(\"Error saving figure:\", e)\n",
    "            return\n",
    "\n",
    "        # Save settings to JSON\n",
    "        with open(json_name, \"w\") as jf:\n",
    "            json.dump(final_settings, jf, indent=2)\n",
    "        # Overwrite config.json so it can be reloaded later\n",
    "        with open(\"config.json\", \"w\") as jf:\n",
    "            json.dump(final_settings, jf, indent=2)\n",
    "\n",
    "        print(f\"Figure saved:\\n  HTML: {html_name}\\n  PDF: {pdf_name}\")\n",
    "        print(f\"Settings saved:\\n  JSON: {json_name}\")\n",
    "        print(\"You can re-load these exact settings (including min/max) later.\")\n",
    "\n",
    "save_figure_button.on_click(on_save_figure_click)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# A) SEARCH WIDGETS (partial NAME => highlight)\n",
    "###############################################################################\n",
    "global_figw_for_search = None  # we set it when we generate the plot\n",
    "\n",
    "search_input_dynamic = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"Enter partial NAME to search (use ; for multiple)\",\n",
    "    description=\"Search NAME:\",\n",
    "    layout={'width': '300px'}\n",
    ")\n",
    "search_button_dynamic = widgets.Button(description=\"Search\", button_style=\"primary\")\n",
    "clear_search_button_dynamic = widgets.Button(description=\"Clear Search\", button_style=\"warning\")\n",
    "\n",
    "def on_search_button_click_dynamic(b):\n",
    "    \"\"\"\n",
    "    Allows multiple queries separated by semicolons.\n",
    "    Each query spawns its own highlight trace named after that query.\n",
    "    \"\"\"\n",
    "    if global_figw_for_search is None:\n",
    "        print(\"No figure built yet! Please 'Generate Plot' first.\")\n",
    "        return\n",
    "    \n",
    "    raw_value = search_input_dynamic.value.strip()\n",
    "    if not raw_value:\n",
    "        print(\"Please enter one or more partial NAME substrings, separated by semicolons.\")\n",
    "        return\n",
    "    \n",
    "    queries = [q.strip() for q in raw_value.split(\";\") if q.strip()]\n",
    "    if not queries:\n",
    "        print(\"No valid queries found (check input).\")\n",
    "        return\n",
    "    \n",
    "    for q in queries:\n",
    "        mask = merged_df[\"NAME\"].str.contains(q, case=False, na=False)\n",
    "        matched = merged_df[mask]\n",
    "        if matched.empty:\n",
    "            print(f\"[{q}] No matches found.\")\n",
    "            continue\n",
    "\n",
    "        # highlight each query in a new scatter\n",
    "        global_figw_for_search.add_scatter(\n",
    "            x=matched[\"scaled_PEAKavg\"],\n",
    "            y=matched[\"IPTMavg\"],\n",
    "            mode=\"markers+text\",\n",
    "            showlegend=False,             # <--- Hide from legend\n",
    "            marker=dict(symbol=\"circle-open\", size=8, line=dict(width=2, color=\"red\")),\n",
    "            text=[q]*len(matched),\n",
    "            textposition=\"top center\",\n",
    "            name=q,  # legend uses the query\n",
    "            hoverinfo=\"skip\"\n",
    "        )\n",
    "        print(f\"[{q}] Found {len(matched)} match(es). Highlights added.\")\n",
    "\n",
    "def on_clear_search_button_click_dynamic(b):\n",
    "    if global_figw_for_search is None:\n",
    "        print(\"No figure built yet!\")\n",
    "        return\n",
    "    # Remove all traces with name == \"Search Highlight\"\n",
    "    # If you prefer to remove traces named after each query, you can adapt it accordingly.\n",
    "    to_remove = [i for i,t in enumerate(global_figw_for_search.data) if t.name == \"Search Highlight\"]\n",
    "    if not to_remove:\n",
    "        print(\"No search highlights to clear.\")\n",
    "        return\n",
    "    for idx in sorted(to_remove, reverse=True):\n",
    "        global_figw_for_search.data = global_figw_for_search.data[:idx] + global_figw_for_search.data[idx+1:]\n",
    "    print(\"Search highlights cleared.\")\n",
    "\n",
    "search_button_dynamic.on_click(on_search_button_click_dynamic)\n",
    "clear_search_button_dynamic.on_click(on_clear_search_button_click_dynamic)\n",
    "search_ui = widgets.HBox([search_input_dynamic, search_button_dynamic, clear_search_button_dynamic])\n",
    "\n",
    "# 6) define selection callback for lasso/box\n",
    "def handle_selection(trace, points, selector):\n",
    "    global global_persisted_indices_dynamic\n",
    "    global_persisted_indices_dynamic.update(points.point_inds)\n",
    "    if not global_persisted_indices_dynamic:\n",
    "        print(\"[Plot] No points selected.\")\n",
    "        return\n",
    "    print(\"[Plot] Accumulated indices:\", global_persisted_indices_dynamic)\n",
    "    sel_df = merged_df.iloc[list(global_persisted_indices_dynamic)]\n",
    "\n",
    "    labels = sel_df[\"name\"]  # or any column\n",
    "    # see if \"Persistent Labels\" trace exists\n",
    "    persist_tr = None\n",
    "    for t in figw.data:\n",
    "        if t.name == \"Persistent Labels\":\n",
    "            persist_tr = t\n",
    "            break\n",
    "    if persist_tr is None:\n",
    "        figw.add_scatter(\n",
    "            x=sel_df[\"scaled_PEAKavg\"],\n",
    "            y=sel_df[\"IPTMavg\"],\n",
    "            mode=\"text\",\n",
    "            text=labels,\n",
    "            textposition=\"top center\",\n",
    "            name=\"Persistent Labels\",\n",
    "            hoverinfo=\"skip\",\n",
    "            textfont=dict(color=\"black\", size=8)\n",
    "        )\n",
    "    else:\n",
    "        persist_tr.x = sel_df[\"scaled_PEAKavg\"]\n",
    "        persist_tr.y = sel_df[\"IPTMavg\"]\n",
    "        persist_tr.text = labels\n",
    "\n",
    "\n",
    "##################################\n",
    "# NEW: handle_click for point click\n",
    "##################################\n",
    "def handle_click(trace, points, state):\n",
    "    \"\"\"\n",
    "    For each clicked point, we label it with NAME + index.\n",
    "    We gather all clicked points in a single \"Clicked Labels\" scatter trace.\n",
    "    \"\"\"\n",
    "    if not points.point_inds:\n",
    "        return\n",
    "\n",
    "    # We'll allow multiple clicks, so let's accumulate them in a separate trace\n",
    "    clicked_trace = None\n",
    "    for t in figw.data:\n",
    "        if t.name == \"Clicked Labels\":\n",
    "            clicked_trace = t\n",
    "            break\n",
    "\n",
    "    # If no \"Clicked Labels\" trace, create one\n",
    "    if clicked_trace is None:\n",
    "        figw.add_scatter(\n",
    "            x=[], \n",
    "            y=[], \n",
    "            mode=\"text\",\n",
    "            text=[],\n",
    "            textposition=\"top center\",\n",
    "            name=\"Clicked Labels\",\n",
    "            showlegend=False,             # <--- Hide from legend\n",
    "\n",
    "            hoverinfo=\"skip\",\n",
    "            textfont=dict(color=\"blue\", size=8)\n",
    "        )\n",
    "        # re‑find it\n",
    "        for t in figw.data:\n",
    "            if t.name == \"Clicked Labels\":\n",
    "                clicked_trace = t\n",
    "                break\n",
    "\n",
    "    # For each clicked point index, add the label\n",
    "    for i in points.point_inds:\n",
    "        row = merged_df.iloc[i]\n",
    "        x_val = row[\"scaled_PEAKavg\"]\n",
    "        y_val = row[\"IPTMavg\"]\n",
    "        label_txt = f\"{row['NAME']} (index={row['index']})\"\n",
    "\n",
    "        # Append to existing arrays\n",
    "        clicked_trace.x = list(clicked_trace.x) + [x_val]\n",
    "        clicked_trace.y = list(clicked_trace.y) + [y_val]\n",
    "        clicked_trace.text = list(clicked_trace.text) + [label_txt]\n",
    "\n",
    "    print(\"[Click] Labeled points:\", points.point_inds)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# B) GROUP HIGHLIGHT WIDGETS\n",
    "###############################################################################\n",
    "group_highlight_input_dynamic = widgets.Text(\n",
    "    value=\"(245,22,250,743,690,261,233,229,479,464,107,1,203,660,659,648,363,462,474,475,492,271,192,97=blue)\",\n",
    "    placeholder=\"(1,5=green) (2,9=red)\",\n",
    "    description=\"Multi-Groups:\",\n",
    "    layout={'width': '600px'}\n",
    ")\n",
    "group_highlight_button_dynamic = widgets.Button(\n",
    "    description=\"Highlight Groups\",\n",
    "    tooltip=\"Highlight multiple index groups\",\n",
    "    button_style=\"info\"\n",
    ")\n",
    "\n",
    "def on_group_highlight_button_click_dynamic(b):\n",
    "    if global_figw_for_search is None:\n",
    "        print(\"No figure built yet! Please 'Generate Plot' first.\")\n",
    "        return\n",
    "    \n",
    "    input_str = group_highlight_input_dynamic.value.strip()\n",
    "    if not input_str:\n",
    "        print(\"No group spec. Format: (1,5=red) (2,9=blue)\")\n",
    "        return\n",
    "    group_specs = [chunk.strip() for chunk in input_str.split(\")\") if chunk.strip()]\n",
    "\n",
    "    for spec in group_specs:\n",
    "        if spec.startswith(\"(\"):\n",
    "            spec = spec[1:].strip()\n",
    "        if \"=\" in spec:\n",
    "            left_part, color_part = spec.split(\"=\",1)\n",
    "            idx_str = left_part.strip()\n",
    "            color_str = color_part.strip()\n",
    "        else:\n",
    "            idx_str = spec\n",
    "            color_str = \"red\"\n",
    "        idx_list = [x.strip() for x in idx_str.split(\",\") if x.strip()]\n",
    "\n",
    "        matched = merged_df[merged_df[\"index\"].isin(idx_list)]\n",
    "        if matched.empty:\n",
    "            print(f\"No match for indices {idx_list}\")\n",
    "            continue\n",
    "\n",
    "        # label with \"name\"\n",
    "        group_label = matched[\"name\"]\n",
    "        global_figw_for_search.add_scatter(\n",
    "            x=matched[\"scaled_PEAKavg\"],\n",
    "            y=matched[\"IPTMavg\"],\n",
    "            mode=\"markers+text\",\n",
    "            showlegend=False,             # <--- Hide from legend\n",
    "            marker=dict(symbol=\"circle\", color=color_str, size=5, opacity=0.5),\n",
    "            text=group_label,\n",
    "            textfont=dict(size=6),\n",
    "            textposition=\"top center\",\n",
    "            name=\"Highlight (Dynamic)\",\n",
    "            hoverinfo=\"skip\"\n",
    "        )\n",
    "        print(f\"Highlighted {len(matched)} points in color '{color_str}'.\")\n",
    "    print(\"Group highlight done.\")\n",
    "\n",
    "group_highlight_button_dynamic.on_click(on_group_highlight_button_click_dynamic)\n",
    "group_ui = widgets.HBox([group_highlight_input_dynamic, group_highlight_button_dynamic])\n",
    "\n",
    "# 1) Define the button\n",
    "clear_labels_button = widgets.Button(\n",
    "    description=\"Clear Labels\",\n",
    "    button_style=\"warning\"\n",
    ")\n",
    "\n",
    "# 2) Define the callback\n",
    "def on_clear_labels_click(b):\n",
    "    if global_figw_for_search is None:\n",
    "        print(\"No figure to clear labels from!\")\n",
    "        return\n",
    "\n",
    "    # We can remove both \"Persistent Labels\" and \"Clicked Labels\" if they exist\n",
    "    names_to_remove = [\"Persistent Labels\", \"Clicked Labels\"]\n",
    "\n",
    "    # Gather indices in reverse to remove them from global_figw_for_search.data\n",
    "    to_remove = []\n",
    "    for i, trace in enumerate(global_figw_for_search.data):\n",
    "        if trace.name in names_to_remove:\n",
    "            to_remove.append(i)\n",
    "    \n",
    "    if not to_remove:\n",
    "        print(\"No persistent/clicked labels to clear.\")\n",
    "        return\n",
    "\n",
    "    for i in sorted(to_remove, reverse=True):\n",
    "        global_figw_for_search.data = (\n",
    "            global_figw_for_search.data[:i] + global_figw_for_search.data[i+1:]\n",
    "        )\n",
    "    print(\"Cleared persistent/clicked label traces.\")\n",
    "\n",
    "# 3) Bind the callback\n",
    "clear_labels_button.on_click(on_clear_labels_click)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# C) EXPORT SELECTED POINTS TO CSV\n",
    "###############################################################################\n",
    "file_name_widget_dynamic = widgets.Text(\n",
    "    value=\"selected_data_dynamic.csv\",\n",
    "    placeholder=\"Enter file name\",\n",
    "    description=\"Save CSV as:\",\n",
    "    disabled=False,\n",
    "    layout={'width': '300px'}\n",
    ")\n",
    "save_data_button_dynamic = widgets.Button(description=\"Save Data\", button_style=\"success\")\n",
    "save_data_output_dynamic = widgets.Output()\n",
    "\n",
    "def on_save_data_click_dynamic(b):\n",
    "    with save_data_output_dynamic:\n",
    "        save_data_output_dynamic.clear_output()\n",
    "        if not global_persisted_indices_dynamic:\n",
    "            print(\"No points selected. Nothing to save.\")\n",
    "            return\n",
    "        \n",
    "        # selected subseta\n",
    "        selected_df = merged_df.iloc[list(global_persisted_indices_dynamic)]\n",
    "        \n",
    "        suffix_input = save_figure_suffix.value.strip()\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if suffix_input:\n",
    "            suffix_str = f\"_{suffix_input}_{timestamp}\"\n",
    "        else:\n",
    "            suffix_str = f\"_{timestamp}\"\n",
    "\n",
    "        \n",
    "        csv_name  = os.path.join(output_dir, f\"AF_plot_selected_hits{suffix_input}.csv\")\n",
    "        if not csv_name:\n",
    "            print(\"Please enter a valid file name first.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            out_path = csv_name  # or os.path.join(output_dir, csv_name)\n",
    "            selected_df.to_csv(out_path, index=False)\n",
    "            print(f\"Saved {len(selected_df)} selected rows to '{out_path}'.\")\n",
    "        except Exception as e:\n",
    "            print(\"Error saving CSV:\", e)\n",
    "\n",
    "\n",
    "save_data_button_dynamic.on_click(on_save_data_click_dynamic)\n",
    "display(Markdown(\"### Click the load & Apply config button first!\"))\n",
    "display(load_button)\n",
    "display(load_output)\n",
    "display(Markdown(\"### Adjust Ranges & Color Scale\"))\n",
    "display(widgets.HBox([color_scale_selector, reverse_scale_checkbox]))\n",
    "display(Markdown(\"**Color Range**\"))\n",
    "display(widgets.HBox([color_min_box, color_max_box]))\n",
    "display(Markdown(\"**Size Range**\"))\n",
    "display(widgets.HBox([size_min_box, size_max_box]))\n",
    "display(Markdown(\"**Opacity Range** (Decrease upper value to increase visibility)\"))\n",
    "display(widgets.HBox([opac_min_box, opac_max_box]))\n",
    "\n",
    "display(Markdown(\"**Note**: You can save the path of the config json file in Cell 1 to load later.\"))\n",
    "\n",
    "\n",
    "display(Markdown(\"### 4) Generate Plot with chosen ranges\"))\n",
    "display(generate_plot_button)\n",
    "\n",
    "display(Markdown(\"### Searching & Group Highlight\"))\n",
    "display(Markdown(\"**Enter multiple semi-colon seperated values to retrieve partial matches in the search 'NAME box'.**\"))\n",
    "\n",
    "display(search_ui)\n",
    "# Finally, display the button\n",
    "\n",
    "display(Markdown(\"**Enter multiple comma seperated index value and the color you want to use for highlighing 'NAME box'.**\"))\n",
    "\n",
    "display(group_ui)\n",
    "display(plot_output)\n",
    "\n",
    "display(Markdown(\"### Save Figure & Settings & Export Selected Points to CSV\"))\n",
    "display(widgets.HBox([save_figure_suffix, save_figure_button]))\n",
    "display([save_figure_output,save_data_output_dynamic])\n",
    "display(save_data_output_dynamic)\n",
    "display(widgets.HBox([file_name_widget_dynamic, save_data_button_dynamic]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ms_analysis",
   "language": "python",
   "name": "ms_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
