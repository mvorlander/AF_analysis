{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1. **Set file paths and options** in the **Setup** cell:\n",
    "   - `iptm_file_path`: Path to the IPTM vs. PEAK file (required).\n",
    "   - `spoc_file_path`: Path to the SPOC score file (optional).\n",
    "   - `SPOC_analysis`: Set to `True` if you want to do SPOC-based analysis (requires a valid SPOC file), otherwise `False`.\n",
    "   - `output_dir`: Where to save charts and selected data (defaults to creating an \"analysis\" folder next to your IPTM file).\n",
    "\n",
    "2. **Run the notebook cells in order**:\n",
    "   - The second cell loads the IPTM data and checks whether to proceed with SPOC or basic analysis.\n",
    "   - If SPOC analysis is enabled and the file is provided, the subsequent cells will merge data and show the SPOC-based chart.\n",
    "   - Otherwise, you'll see the basic IPTM vs. PEAK chart.\n",
    "\n",
    "3. **Interact with the charts**:\n",
    "   - Use **Lasso/Box select** to label points persistently.\n",
    "   - Use the **Search** widget to highlight points by partial name.\n",
    "   - **Clear** labels or search highlights as needed.\n",
    "   - **Save** the plot as HTML/PDF or **export** selected data as a CSV.\n",
    "\n",
    "4. **Check the output directory** for your saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 1: BASIC SETUP ===\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "from plotly.graph_objs import FigureWidget\n",
    "\n",
    "# ---------------- USER INPUTS ----------------\n",
    "# Required: path to the IPTM vs. PEAK file\n",
    "iptm_file_path = \"/Volumes/plaschka/shared/alphafold/matthias.vorlaender/screens/transcription_complexes/2025-03-05_PolII_subunits_uniprot_vs_RPB3_FLAG_DNase_vs_wt_DNaseI_without_PDB_IDs/IPTM_vs_PTM.txt\"\n",
    "\n",
    "\n",
    "# Optional: path to the SPOC file\n",
    "#Set None if not available\n",
    "spoc_file_path = \"/Volumes/plaschka/shared/alphafold/matthias.vorlaender/screens/transcription_complexes/2025-03-05_PolII_subunits_uniprot_vs_RPB3_FLAG_DNase_vs_wt_DNaseI_without_PDB_IDs/spoc_dir_SPOC_analysis.csv\"\n",
    "\n",
    "# Boolean flag indicating whether you want to do SPOC analysis\n",
    "SPOC_analysis = True  # or False\n",
    "\n",
    "# Output directory (default is a subfolder 'analysis' next to the IPTM file)\n",
    "# If you want to override, set output_dir = \"/your/desired/output\"\n",
    "default_base = os.path.dirname(iptm_file_path)  # Folder of the IPTM file\n",
    "default_out = os.path.join(default_base, \"analysis\")\n",
    "output_dir = default_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPTM file path   : /Volumes/plaschka/shared/alphafold/matthias.vorlaender/screens/transcription_complexes/2025-03-05_PolII_subunits_uniprot_vs_RPB3_FLAG_DNase_vs_wt_DNaseI_without_PDB_IDs/IPTM_vs_PTM.txt\n",
      "SPOC file path   : /Volumes/plaschka/shared/alphafold/matthias.vorlaender/screens/transcription_complexes/2025-03-05_PolII_subunits_uniprot_vs_RPB3_FLAG_DNase_vs_wt_DNaseI_without_PDB_IDs/spoc_dir_SPOC_analysis.csv\n",
      "SPOC_analysis    : True\n",
      "Output directory : /Volumes/plaschka/shared/alphafold/matthias.vorlaender/screens/transcription_complexes/2025-03-05_PolII_subunits_uniprot_vs_RPB3_FLAG_DNase_vs_wt_DNaseI_without_PDB_IDs/analysis\n",
      "Loaded IPTM DataFrame with shape: (794, 10)\n",
      "Created 'IPTM_max' column with the maximum IPTM score for each row.\n",
      "SPOC analysis is True, and a SPOC file is provided. We will proceed with SPOC-based code.\n",
      "Loading SPOC file and merging with IPTM data...\n",
      "SPOC DataFrame shape: (233, 30)\n",
      "Merged DataFrame shape: (794, 41)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### SPOC Hover-Column Selection"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0216d87da67447929925fb6e62845e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Hover Columns:', index=(0, 1, 6, 12), layout=Layout(width='400px'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"IPTM file path   :\", iptm_file_path)\n",
    "print(\"SPOC file path   :\", spoc_file_path)\n",
    "print(\"SPOC_analysis    :\", SPOC_analysis)\n",
    "print(\"Output directory :\", output_dir)\n",
    "\n",
    "# === STEP 2: LOAD IPTM & BRANCH ===\n",
    "\n",
    "# Load the IPTM vs. PEAK data\n",
    "df_iptm = pd.read_csv(iptm_file_path, sep=\"\\t\")\n",
    "print(\"Loaded IPTM DataFrame with shape:\", df_iptm.shape)\n",
    "\n",
    "def extract_max_from_iptm(value):\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        # Convert the value to string and split on colon\n",
    "        parts = str(value).split(\":\")\n",
    "        # Convert each part to a float, ignoring parts that cannot be converted\n",
    "        nums = []\n",
    "        for part in parts:\n",
    "            try:\n",
    "                nums.append(float(part))\n",
    "            except:\n",
    "                pass\n",
    "        if nums:\n",
    "            return max(nums)\n",
    "        else:\n",
    "            return np.nan\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function row-wise to create a new column \"IPTM_max\"\n",
    "df_iptm[\"IPTM_max\"] = df_iptm[\"IPTM\"].apply(extract_max_from_iptm)\n",
    "print(\"Created 'IPTM_max' column with the maximum IPTM score for each row.\")\n",
    "\n",
    "if SPOC_analysis and spoc_file_path is not None:\n",
    "    print(\"SPOC analysis is True, and a SPOC file is provided. We will proceed with SPOC-based code.\")\n",
    "else:\n",
    "    print(\"Either SPOC_analysis is False or no SPOC file is provided.\")\n",
    "    print(\"Proceed with Basic Bubble Chart (equivalent to old cell #2).\")\n",
    "\n",
    "# === STEP 3: SPOC MERGE & HOVER SETUP ===\n",
    "if SPOC_analysis and spoc_file_path is not None:\n",
    "    print(\"Loading SPOC file and merging with IPTM data...\")\n",
    "    df_spoc = pd.read_csv(spoc_file_path)\n",
    "    print(\"SPOC DataFrame shape:\", df_spoc.shape)\n",
    "    \n",
    "    # Merge the two DataFrames\n",
    "    merged_df = pd.merge(\n",
    "        df_iptm,\n",
    "        df_spoc,\n",
    "        left_on=\"NAME\",\n",
    "        right_on=\"complex_name\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    print(\"Merged DataFrame shape:\", merged_df.shape)\n",
    "    \n",
    "    # === 1) Create an \"opacity\" column based on spoc_score ===\n",
    "    if \"spoc_score\" in merged_df.columns and merged_df[\"spoc_score\"].notnull().any():\n",
    "        min_score = merged_df[\"spoc_score\"].min()\n",
    "        max_score = 1.0  # forcing maximum to 1.0\n",
    "        def compute_opacity(score):\n",
    "            if pd.isnull(score):\n",
    "                return 0.1\n",
    "            if max_score == min_score:\n",
    "                return 1.0\n",
    "            return 0.1 + (score - min_score) / (max_score - min_score) * (1.0 - 0.1)\n",
    "        merged_df[\"opacity\"] = merged_df[\"spoc_score\"].apply(compute_opacity)\n",
    "    else:\n",
    "        merged_df[\"opacity\"] = 1.0\n",
    "\n",
    "    # === 2) Parse short name from \"NAME\" and store in new column ===\n",
    "    def parse_shortname(full_name):\n",
    "        \"\"\"\n",
    "        Given something like:\n",
    "          \"76_sp-Q92610-ZN592_HUMAN_vs_sp-Q13889-TF2H3_HUMAN\"\n",
    "        Extract the short name from the target portion\n",
    "          -> \"TF2H3\"\n",
    "        \"\"\"\n",
    "        if pd.isnull(full_name):\n",
    "            return None\n",
    "        try:\n",
    "            left_vs_right = full_name.split(\"_vs_\")\n",
    "            target_part = left_vs_right[1]  # e.g. \"sp-Q13889-TF2H3_HUMAN\"\n",
    "            chunks = target_part.split(\"-\")\n",
    "            if len(chunks) < 3:\n",
    "                return target_part\n",
    "            # e.g. chunks[2] = \"TF2H3_HUMAN\"\n",
    "            return chunks[2].split(\"_\")[0]  # \"TF2H3\"\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    merged_df[\"protein_name_hit\"] = merged_df[\"NAME\"].apply(parse_shortname)\n",
    "\n",
    "    # === 3) Build default hover text ===\n",
    "    default_hover_columns = [\"NAME\", \"IPTM\", \"PEAK\", \"spoc_score\"]\n",
    "    # We can also add \"protein_name_hit\" to the default hover if you want\n",
    "    # default_hover_columns.append(\"protein_name_hit\")\n",
    "\n",
    "    for col in default_hover_columns:\n",
    "        if col not in merged_df.columns:\n",
    "            default_hover_columns.remove(col)\n",
    "\n",
    "    merged_df[\"hover_text\"] = merged_df.apply(\n",
    "        lambda row: \"<br>\".join([f\"{col}: {row[col]}\" for col in default_hover_columns]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # === 4) Build the hover selection widget ===\n",
    "    # This widget uses 'available_hover_columns', which now includes 'protein_name_hit'\n",
    "    available_hover_columns = list(merged_df.columns)\n",
    "    # Pre-select defaults\n",
    "    if default_hover_columns:\n",
    "        preselected = tuple(default_hover_columns)\n",
    "    else:\n",
    "        preselected = (available_hover_columns[0],)  # fallback\n",
    "\n",
    "    hover_columns_selector = widgets.SelectMultiple(\n",
    "        options=available_hover_columns,\n",
    "        value=preselected,\n",
    "        description=\"Hover Columns:\",\n",
    "        disabled=False,\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "\n",
    "    update_hover_button = widgets.Button(\n",
    "        description=\"Update Hover Info\",\n",
    "        button_style=\"primary\"\n",
    "    )\n",
    "    \n",
    "    def update_hover_info(b):\n",
    "        selected_columns = list(hover_columns_selector.value)\n",
    "        if not selected_columns:\n",
    "            print(\"Please select at least one column for hover info.\")\n",
    "            return\n",
    "        merged_df[\"hover_text\"] = merged_df.apply(\n",
    "            lambda row: \"<br>\".join([f\"{col}: {row[col]}\" for col in default_hover_columns]),\n",
    "            axis=1\n",
    "        )\n",
    "        print(\"Hover info updated using columns:\", selected_columns)\n",
    "    \n",
    "    update_hover_button.on_click(update_hover_info)\n",
    "\n",
    "    display(Markdown(\"### SPOC Hover-Column Selection\"))\n",
    "    display(widgets.HBox([hover_columns_selector, update_hover_button]))\n",
    "\n",
    "else:\n",
    "    print(\"Skipping SPOC merge and hover setup because SPOC_analysis=False or no SPOC file provided.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 4a: SPOC-BASED BUBBLE CHART ===\n",
    "import re\n",
    "from plotly.colors import sample_colorscale\n",
    "\n",
    "# Global variable to store the current hover column selection.\n",
    "# Initialize with the default hover columns.\n",
    "current_hover_columns = default_hover_columns\n",
    "\n",
    "def update_hover_info(b):\n",
    "    global current_hover_columns\n",
    "    selected_columns = list(hover_columns_selector.value)\n",
    "    if not selected_columns:\n",
    "        print(\"Please select at least one column for hover info.\")\n",
    "        return\n",
    "    current_hover_columns = selected_columns\n",
    "\n",
    "    merged_df[\"hover_text\"] = merged_df.apply(\n",
    "        lambda row: \"<br>\".join([f\"{col}: {row[col]}\" for col in  selected_columns]),\n",
    "        axis=1\n",
    "    )\n",
    "    print(\"Hover info updated using columns:\", selected_columns)\n",
    "\n",
    "update_hover_button.on_click(update_hover_info)\n",
    "\n",
    "def parse_name_field(name_str):\n",
    "    \"\"\"\n",
    "    Given a string of form:\n",
    "       \"76_sp-Q92610-ZN592_HUMAN_vs_sp-Q13889-TF2H3_HUMAN\"\n",
    "    return a dict with:\n",
    "       {\n",
    "         'index': '76',\n",
    "         'protein1': 'sp-Q92610-ZN592_HUMAN',\n",
    "         'protein2': 'sp-Q13889-TF2H3_HUMAN'\n",
    "       }\n",
    "    If parsing fails, returns something fallback with empty strings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split around '_vs_'\n",
    "        parts = name_str.split(\"_vs_\")\n",
    "        left_part = parts[0]  # e.g. \"76_sp-Q92610-ZN592_HUMAN\"\n",
    "        right_part = parts[1] # e.g. \"sp-Q13889-TF2H3_HUMAN\"\n",
    "\n",
    "        # Now split the left_part on the first underscore, to separate index from protein1\n",
    "        left_sub = left_part.split(\"_\", 1)\n",
    "        idx = left_sub[0]  # \"76\"\n",
    "        prot1 = left_sub[1]  # \"sp-Q92610-ZN592_HUMAN\"\n",
    "\n",
    "        return {\n",
    "            \"index\": idx,\n",
    "            \"protein1\": prot1,\n",
    "            \"protein2\": right_part\n",
    "        }\n",
    "    except Exception:\n",
    "        # If something goes wrong, return placeholders\n",
    "        return {\n",
    "            \"index\": \"\",\n",
    "            \"protein1\": \"\",\n",
    "            \"protein2\": \"\"\n",
    "        }\n",
    "\n",
    "def parse_color(color_str):\n",
    "    \"\"\"Converts a hex or rgb(a) color string to (r, g, b).\"\"\"\n",
    "    # This helper is used if you need numeric r,g,b from a string.\n",
    "    # If you only need to pass e.g. \"red\" or \"#ff0000\" to Plotly,\n",
    "    # you can skip converting to (r,g,b). Plotly can handle them directly.\n",
    "    if color_str.startswith(\"#\"):\n",
    "        hex_color = color_str.lstrip(\"#\")\n",
    "        r, g, b = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "        return r, g, b\n",
    "    elif color_str.startswith(\"rgb\"):\n",
    "        nums = re.findall(r'\\d+', color_str)\n",
    "        r, g, b = tuple(int(n) for n in nums[:3])\n",
    "        return r, g, b\n",
    "    else:\n",
    "        # Try named CSS color (e.g. \"red\", \"blue\") - Plotly accepts those directly\n",
    "        return color_str\n",
    "\n",
    "# Before building the figure, let's ensure 'index' is in merged_df\n",
    "if SPOC_analysis and spoc_file_path is not None:\n",
    "    if \"index\" not in merged_df.columns:\n",
    "        # Parse once for all rows\n",
    "        parsed_info = merged_df[\"NAME\"].apply(parse_name_field).apply(pd.Series)\n",
    "        merged_df = pd.concat([merged_df, parsed_info], axis=1)\n",
    "        # Ensure 'index' column is treated as a string\n",
    "        merged_df[\"index\"] = merged_df[\"index\"].astype(str)\n",
    "\n",
    "    # Build the scatter figure\n",
    "    fig = px.scatter(\n",
    "        merged_df,\n",
    "        x=\"scaled_PEAKavg\",\n",
    "        y=\"IPTMavg\",\n",
    "        size=\"IPTM_max\",\n",
    "        color=\"scaled_PEAKavg\",\n",
    "        color_continuous_scale=\"viridis_r\",\n",
    "        title=\"(SPOC) IPTM vs. Scaled PEAKavg\",\n",
    "        labels={\"IPTMavg\": \"IPTMavg\", \"scaled_PEAKavg\": \"Scaled PEAKavg\"}\n",
    "    )\n",
    "\n",
    "    # Build color array with custom opacity\n",
    "    min_val = merged_df[\"scaled_PEAKavg\"].min()\n",
    "    max_val = merged_df[\"scaled_PEAKavg\"].max()\n",
    "    if max_val != min_val:\n",
    "        norm = (merged_df[\"scaled_PEAKavg\"] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        norm = merged_df[\"scaled_PEAKavg\"] * 0  # or just 0\n",
    "\n",
    "    base_colors = px.colors.sequential.Viridis_r\n",
    "    rgba_colors = []\n",
    "    for val, opa in zip(norm, merged_df[\"opacity\"]):\n",
    "        color_str = sample_colorscale(base_colors, val)[0]  # returns a color string\n",
    "        try:\n",
    "            r, g, b = parse_color(color_str)\n",
    "            if isinstance(r, str):\n",
    "                # color was a named CSS color\n",
    "                rgba_colors.append(r) \n",
    "            else:\n",
    "                rgba_colors.append(f\"rgba({r},{g},{b},{opa})\")\n",
    "        except:\n",
    "            rgba_colors.append(f\"rgba(0,0,0,{opa})\")\n",
    "\n",
    "    fig.update_traces(\n",
    "        marker=dict(color=rgba_colors),\n",
    "        customdata=merged_df[[\"hover_text\"]].values,\n",
    "        hovertemplate=\"%{customdata[0]}<extra></extra>\"\n",
    "    )\n",
    "        \n",
    "    fig.update_layout(\n",
    "        # Update x and y axes: no grid, with black axis lines.\n",
    "        xaxis=dict(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor='black'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor='black'\n",
    "        ),\n",
    "        # Add a rectangle shape as an outer border.\n",
    "        shapes=[\n",
    "            dict(\n",
    "                type=\"rect\",\n",
    "                xref=\"paper\", yref=\"paper\",\n",
    "                x0=0, y0=0, x1=1, y1=1,\n",
    "                line=dict(color=\"black\", width=2)\n",
    "            )\n",
    "        ],\n",
    "        # Optionally, set the template and margins.\n",
    "        template=\"plotly_white\",\n",
    "        margin=dict(l=50, r=50, t=50, b=50)\n",
    "    )\n",
    "        \n",
    "    figw = FigureWidget(fig)\n",
    "\n",
    "    # --- GLOBAL STORAGE FOR SELECTIONS ---\n",
    "    global_persisted_indices_spoc = set()\n",
    "\n",
    "    def handle_selection(trace, points, selector):\n",
    "        global global_persisted_indices_spoc\n",
    "        global_persisted_indices_spoc.update(points.point_inds)\n",
    "        if not global_persisted_indices_spoc:\n",
    "            print(\"No points selected.\")\n",
    "            return\n",
    "        print(\"Accumulated selected indices:\", global_persisted_indices_spoc)\n",
    "        selected_df = merged_df.iloc[list(global_persisted_indices_spoc)]\n",
    "        \n",
    "        # Example label: extract a short uniprot name from 'NAME' or just show the \"index\"\n",
    "        def process_name(name_str):\n",
    "            try:\n",
    "                parts = name_str.split(\"_vs_\")\n",
    "                if len(parts) < 2:\n",
    "                    return name_str\n",
    "                # E.g. \"sp-Q13889-TF2H3_HUMAN\"\n",
    "                hit = parts[1]\n",
    "                hit_parts = hit.split(\"-\")\n",
    "                if len(hit_parts) < 3:\n",
    "                    return hit\n",
    "                return hit_parts[2].split(\"_\")[0]\n",
    "            except:\n",
    "                return name_str\n",
    "        \n",
    "        labels = selected_df[\"NAME\"].apply(process_name)\n",
    "        \n",
    "        # Check if we already have a \"Persistent Labels\" trace\n",
    "        persistent_trace = None\n",
    "        for t in figw.data:\n",
    "            if t.name == \"Persistent Labels\":\n",
    "                persistent_trace = t\n",
    "                break\n",
    "        \n",
    "        if persistent_trace is None:\n",
    "            figw.add_scatter(\n",
    "                x=selected_df[\"scaled_PEAKavg\"],\n",
    "                y=selected_df[\"IPTMavg\"],\n",
    "                mode=\"text\",\n",
    "                text=labels,\n",
    "                textposition=\"top center\",\n",
    "                name=\"Persistent Labels\",\n",
    "                hoverinfo=\"skip\",\n",
    "                textfont=dict(color=\"black\", size=12)\n",
    "            )\n",
    "        else:\n",
    "            persistent_trace.x = selected_df[\"scaled_PEAKavg\"]\n",
    "            persistent_trace.y = selected_df[\"IPTMavg\"]\n",
    "            persistent_trace.text = labels\n",
    "\n",
    "    # Attach selection callback\n",
    "    for trace in figw.data:\n",
    "        trace.on_selection(handle_selection)\n",
    "\n",
    "    # --- STANDARD SEARCH (by substring) WIDGETS ---\n",
    "    search_input_spoc = widgets.Text(\n",
    "        value=\"\",\n",
    "        placeholder=\"Enter partial name to search\",\n",
    "        description=\"Search NAME:\",\n",
    "        style={'description_width': '120px'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    search_button_spoc = widgets.Button(\n",
    "        description=\"Search\",\n",
    "        tooltip=\"Search partial matches\",\n",
    "        button_style=\"primary\"\n",
    "    )\n",
    "    clear_search_button_spoc = widgets.Button(\n",
    "        description=\"Clear Search\",\n",
    "        tooltip=\"Remove search highlights\",\n",
    "        button_style=\"warning\"\n",
    "    )\n",
    "\n",
    "    def on_search_button_click_spoc(b):\n",
    "        query = search_input_spoc.value.strip()\n",
    "        if not query:\n",
    "            print(\"Please enter a search query.\")\n",
    "            return\n",
    "        mask = merged_df[\"NAME\"].str.contains(query, case=False, na=False)\n",
    "        matched = merged_df[mask]\n",
    "        if matched.empty:\n",
    "            print(\"No matches found.\")\n",
    "            return\n",
    "        \n",
    "        # Add highlight scatter\n",
    "        figw.add_scatter(\n",
    "            x=matched[\"scaled_PEAKavg\"],\n",
    "            y=matched[\"IPTMavg\"],\n",
    "            mode=\"markers+text\",\n",
    "            marker=dict(symbol=\"circle-open\", size=12, line=dict(width=2, color=\"red\")),\n",
    "            text=[query]*len(matched),\n",
    "            textposition=\"top center\",\n",
    "            name=\"Search Highlight\",\n",
    "            hoverinfo=\"skip\"\n",
    "        )\n",
    "        print(f\"Found {len(matched)} match(es). Highlights added.\")\n",
    "\n",
    "    def on_clear_search_button_click_spoc(b):\n",
    "        indices_to_remove = [i for i, t in enumerate(figw.data) if t.name == \"Search Highlight\"]\n",
    "        if not indices_to_remove:\n",
    "            print(\"No search highlights to clear.\")\n",
    "            return\n",
    "        for idx in sorted(indices_to_remove, reverse=True):\n",
    "            figw.data = figw.data[:idx] + figw.data[idx+1:]\n",
    "        print(\"Search highlights cleared.\")\n",
    "    \n",
    "    search_button_spoc.on_click(on_search_button_click_spoc)\n",
    "    clear_search_button_spoc.on_click(on_clear_search_button_click_spoc)\n",
    "\n",
    "    # --- NEW MULTI-GROUP INDEX + COLOR HIGHLIGHT ---\n",
    "    # Example input: (1,5,12,19=green) (2,9,200=red)\n",
    "    group_highlight_input_spoc = widgets.Text(\n",
    "        ##TRICK THE COPY PASTE BIUG HERE!!###\n",
    "        value=\"(322,245,22,250,743,690,261,233,229,479,464,107,1,203,660,659,648,363,462,474,475,492,271,192,97=green) (33=grey) (591,425,761,771,286,385,233,479,464,203,660,659,648,462,474,492,192,508,181,190,64,579,40,708,364,416,35,151=red) (436,117,630,573,3,60,687=black)(400,411,423=blue)\",\n",
    "        placeholder=\"(192,97=green) (35,151=red)\",\n",
    "        description=\"Multi-Groups:\",\n",
    "        style={'description_width': '100px'},\n",
    "        layout={'width': '600px'}\n",
    "    )\n",
    "    group_highlight_button_spoc = widgets.Button(\n",
    "        description=\"Highlight Groups\",\n",
    "        tooltip=\"Highlight multiple index groups, each with a color\",\n",
    "        button_style=\"info\"\n",
    "    )\n",
    "\n",
    "    def on_group_highlight_button_click_spoc(b):\n",
    "        \"\"\"\n",
    "        Example input: (743=green) (385,23,151=red) (20,21,423=blue)\n",
    "        Each group is parsed, and for each group we use the protein_name_hit value for labeling.\n",
    "        \"\"\"\n",
    "        input_str = group_highlight_input_spoc.value.strip()\n",
    "        if not input_str:\n",
    "            print(\"No group spec given. Format: (1,5,12=red) (2,9=green)\")\n",
    "            return\n",
    "\n",
    "        # Split by closing parenthesis, filtering out empties.\n",
    "        group_specs = [chunk.strip() for chunk in input_str.split(\")\") if chunk.strip()]\n",
    "\n",
    "        for spec in group_specs:\n",
    "            # Remove any leading \"(\" if present.\n",
    "            if spec.startswith(\"(\"):\n",
    "                spec = spec[1:].strip()\n",
    "\n",
    "            # Split on \"=\" to separate indices from the color.\n",
    "            if \"=\" in spec:\n",
    "                left_part, color_part = spec.split(\"=\", 1)\n",
    "                indices_str = left_part.strip()\n",
    "                color_str = color_part.strip()\n",
    "            else:\n",
    "                indices_str = spec\n",
    "                color_str = \"red\"  # default\n",
    "\n",
    "            # Split indices (comma-separated).\n",
    "            idx_list = [x.strip() for x in indices_str.split(\",\") if x.strip()]\n",
    "            if not idx_list:\n",
    "                print(f\"No valid indices found in '{spec}'\")\n",
    "                continue\n",
    "\n",
    "            # Find all matching rows in merged_df.\n",
    "            matched = merged_df[merged_df[\"index\"].isin(idx_list)]\n",
    "            if matched.empty:\n",
    "                print(f\"No match for indices {idx_list}\")\n",
    "                continue\n",
    "\n",
    "            # Use the protein_name_hit column for labeling.\n",
    "            group_label = matched[\"protein_name_hit\"]\n",
    "\n",
    "            # Add one scatter trace for the group.\n",
    "            figw.add_scatter(\n",
    "                x=matched[\"scaled_PEAKavg\"],\n",
    "                y=matched[\"IPTMavg\"],\n",
    "                mode=\"markers+text\",\n",
    "                marker=dict(symbol=\"circle\", color=color_str, size=12),\n",
    "                text=group_label,\n",
    "                textposition=\"top center\",\n",
    "                name=f\"Highlight\",\n",
    "                hoverinfo=\"skip\"\n",
    "            )\n",
    "            print(f\"Highlighted indices {idx_list} in color '{color_str}'\")\n",
    "\n",
    "        print(\"Group highlight done.\")\n",
    "\n",
    "    group_highlight_button_spoc.on_click(on_group_highlight_button_click_spoc)\n",
    "\n",
    "    # --- CLEAR LABELS & SAVE PLOT ---\n",
    "    clear_labels_button_spoc = widgets.Button(\n",
    "        description=\"Clear Labels\",\n",
    "        button_style=\"warning\"\n",
    "    )\n",
    "    def on_clear_labels_click_spoc(b):\n",
    "        global_persisted_indices_spoc\n",
    "        global_persisted_indices_spoc.clear()\n",
    "\n",
    "        # Remove the \"Persistent Labels\" or highlight traces if needed\n",
    "        names_to_remove = [\"Persistent Labels\"]\n",
    "        # Also remove any highlight traces we might want to clear\n",
    "        # If you only want to remove the \"Persistent Labels\", \n",
    "        # leave out highlight traces from the list above.\n",
    "        indices_to_remove = [\n",
    "            i for i, t in enumerate(figw.data) \n",
    "            if t.name in names_to_remove or t.name.startswith(\"Highlight \")\n",
    "        ]\n",
    "        for idx in sorted(indices_to_remove, reverse=True):\n",
    "            figw.data = figw.data[:idx] + figw.data[idx+1:]\n",
    "        print(\"Persistent labels and highlight traces cleared.\")\n",
    "\n",
    "    clear_labels_button_spoc.on_click(on_clear_labels_click_spoc)\n",
    "\n",
    "    save_plot_button_spoc = widgets.Button(\n",
    "        description=\"Save Plot (HTML & PDF)\",\n",
    "        tooltip=\"Save the current plot\",\n",
    "        button_style=\"info\"\n",
    "    )\n",
    "\n",
    "\n",
    "    file_name_widget_spoc = widgets.Text(\n",
    "        value=\"selected_data_spoc.csv\",\n",
    "        placeholder=\"Enter file name\",\n",
    "        description=\"Save CSV as:\",\n",
    "        disabled=False\n",
    "    )\n",
    "    save_data_button_spoc = widgets.Button(\n",
    "        description=\"Save Data\",\n",
    "        button_style=\"success\"\n",
    "    )\n",
    "    save_data_output_spoc = widgets.Output()\n",
    "    \n",
    "    \n",
    "    import datetime\n",
    "\n",
    "    custom_suffix_save = widgets.Text(\n",
    "        value=\"\",\n",
    "        placeholder=\"Add file name suffix\",\n",
    "        description=\"Filename Suffix:\",\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    \n",
    "    def on_save_plot_click_spoc(b):\n",
    "        try:\n",
    "            # Retrieve custom suffix from widget and current timestamp.\n",
    "            suffix = custom_suffix_save.value.strip()\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            if suffix:\n",
    "                suffix_str = f\"_{suffix}_{timestamp}\"\n",
    "            else:\n",
    "                suffix_str = f\"_{timestamp}\"\n",
    "            \n",
    "            # Build file paths with the custom suffix and timestamp.\n",
    "            html_filename = f\"spoc_bubble_chart{suffix_str}.html\"\n",
    "            pdf_filename = f\"spoc_bubble_chart{suffix_str}.pdf\"\n",
    "            html_path = os.path.join(output_dir, html_filename)\n",
    "            pdf_path = os.path.join(output_dir, pdf_filename)\n",
    "            \n",
    "            # Save the figure.\n",
    "            figw.write_html(html_path)\n",
    "            figw.write_image(pdf_path, format=\"pdf\")\n",
    "            print(f\"Plot saved:\\n  HTML: {html_path}\\n  PDF: {pdf_path}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error saving plot:\", e)\n",
    "\n",
    "    save_plot_button_spoc.on_click(on_save_plot_click_spoc)\n",
    "\n",
    "    # --- DISPLAY ---\n",
    "    instructions_text_spoc = \"\"\"\n",
    "    **SPOC-Based Plot Instructions:**\n",
    "    1. **Use Lasso/Box select to pick points and persist labels**.\n",
    "    2. (Optional) Search by partial `NAME` using the first box, then clear highlights if needed.\n",
    "    3. **Highlight by index** (the digits before the underscore) using the second box, \n",
    "       e.g. (1,5,12,19=green) (2,9,200=red) (20=blue)\n",
    "    4. Clear persistent labels and/or highlight traces if needed.\n",
    "    5. Save the plot (HTML & PDF) or selected data (CSV).\n",
    "    \"\"\"\n",
    "    display(Markdown(instructions_text_spoc))\n",
    "    display(widgets.HBox([search_input_spoc, search_button_spoc, clear_search_button_spoc]))\n",
    "    \n",
    "    # The new multi-index highlight input\n",
    "    # Now just display the new widgets:\n",
    "    display(widgets.HBox([group_highlight_input_spoc, group_highlight_button_spoc]))\n",
    "    display(widgets.HBox([clear_labels_button_spoc]))\n",
    "\n",
    "    display(widgets.HBox([custom_suffix_save, save_plot_button_spoc]))\n",
    "\n",
    "\n",
    "    display(figw)\n",
    "    display(widgets.HBox([file_name_widget_spoc, save_data_button_spoc]))\n",
    "    display(save_data_output_spoc)\n",
    "\n",
    "else:\n",
    "    print(\"Skipping SPOC-based bubble chart...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "TO tricky the copy apste button, search the code for \"##TRICK THE COPY PASTE BIUG HERE!!###\" and enter your hiohglits there!\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MS data with shape: (1681, 4)\n",
      "Extracted target_uniprot in merged_df.\n",
      "Merged DataFrame shape after merging MS data: (794, 49)\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: MERGE MS DATA ===\n",
    "ms_file_path = \"/Volumes/plaschka/shared/data/mass-spec/MS_analysis/analysis/MV_RPB3_FLAG_pretty/exports/merged_data_20250319_182512_with_nuc_vs_chrom.tsv\"\n",
    "df_ms = pd.read_csv(ms_file_path, sep=\"\\t\")\n",
    "print(\"Loaded MS data with shape:\", df_ms.shape)\n",
    "\n",
    "def extract_target_uniprot(name_str):\n",
    "    try:\n",
    "        parts = name_str.split(\"_vs_\")\n",
    "        if len(parts) < 2:\n",
    "            return None\n",
    "        target = parts[1]  # e.g., \"sp-Q9Y3X0-CCDC9_HUMAN\"\n",
    "        target_parts = target.split(\"-\")\n",
    "        if len(target_parts) < 2:\n",
    "            return None\n",
    "        return target_parts[1]  # e.g. \"Q9Y3X0\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Create a new column in merged_df with the target uniprot IDs.\n",
    "merged_df[\"target_uniprot\"] = merged_df[\"NAME\"].apply(extract_target_uniprot)\n",
    "print(\"Extracted target_uniprot in merged_df.\")\n",
    "\n",
    "# Merge the MS data with merged_df on \"Accession\" from MS data and \"target_uniprot\" in merged_df.\n",
    "merged_df = pd.merge(merged_df, df_ms, left_on=\"target_uniprot\", right_on=\"Accession\", how=\"left\")\n",
    "print(\"Merged DataFrame shape after merging MS data:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing config from config.json: {'color_column': 'DNaseI digest chromatin FLAG-mCh_RPB3_normalized_P19387 vs Nucleoplasm FLAG-mCh_RPB3_normalized_P19387', 'size_column': 'spoc_score', 'opacity_column': 'DNaseI digest chromatin FLAG-mCh_RPB3', 'color_transform': 'None', 'size_transform': 'None', 'opacity_transform': 'log2'}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Column & Transform Selection"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1df373aeef445d39e0c2607bf4ca316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Color Col:', index=35, layout=Layout(width='220px'), options=('IPTMavg', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ab486de17d46d0ae0966c631a491d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Color Xform:', layout=Layout(width='220px'), options=('None', 'log2', 'loâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fac96b7af840609e8acea75536efbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Config', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjust columns/transforms as desired, then click 'Save Config'. Next, run Cell 2.\n"
     ]
    }
   ],
   "source": [
    "# === CELL 1: Column & Transform Selection, Save to JSON Config ===\n",
    "import os\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "config_file = \"config.json\"\n",
    "\n",
    "# We assume you already have a DataFrame called merged_df with numeric columns\n",
    "numeric_cols = merged_df.select_dtypes(include=[float, int]).columns.tolist()\n",
    "transform_options = [\"None\", \"log2\", \"log10\"]\n",
    "\n",
    "# If a config already exists, load it. Otherwise define some defaults.\n",
    "if os.path.exists(config_file):\n",
    "    with open(config_file, \"r\") as f:\n",
    "        prev_cfg = json.load(f)\n",
    "    print(f\"Loaded existing config from {config_file}: {prev_cfg}\")\n",
    "else:\n",
    "    prev_cfg = {}\n",
    "    print(\"No config file found; using empty defaults.\")\n",
    "\n",
    "# Helper function to get from dict with fallback\n",
    "def dict_get(d, key, fallback):\n",
    "    return d[key] if key in d else fallback\n",
    "\n",
    "# Column selection\n",
    "color_selector = widgets.Dropdown(\n",
    "    options=numeric_cols,\n",
    "    value=dict_get(prev_cfg, \"color_column\", \"scaled_PEAKavg\"),\n",
    "    description=\"Color Col:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "size_selector = widgets.Dropdown(\n",
    "    options=numeric_cols,\n",
    "    value=dict_get(prev_cfg, \"size_column\", \"spoc_score\"),\n",
    "    description=\"Size Col:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "opacity_selector = widgets.Dropdown(\n",
    "    options=numeric_cols,\n",
    "    value=dict_get(prev_cfg, \"opacity_column\", \"spoc_score\"),\n",
    "    description=\"Opacity Col:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "\n",
    "# Transform selection\n",
    "color_transform_selector = widgets.Dropdown(\n",
    "    options=transform_options,\n",
    "    value=dict_get(prev_cfg, \"color_transform\", \"None\"),\n",
    "    description=\"Color Xform:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "size_transform_selector = widgets.Dropdown(\n",
    "    options=transform_options,\n",
    "    value=dict_get(prev_cfg, \"size_transform\", \"None\"),\n",
    "    description=\"Size Xform:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "opacity_transform_selector = widgets.Dropdown(\n",
    "    options=transform_options,\n",
    "    value=dict_get(prev_cfg, \"opacity_transform\", \"None\"),\n",
    "    description=\"Opac Xform:\",\n",
    "    layout={'width': '220px'}\n",
    ")\n",
    "\n",
    "display(Markdown(\"### Column & Transform Selection\"))\n",
    "display(widgets.HBox([color_selector, size_selector, opacity_selector]))\n",
    "display(widgets.HBox([color_transform_selector, size_transform_selector, opacity_transform_selector]))\n",
    "\n",
    "def on_save_config(b):\n",
    "    cfg = {\n",
    "        \"color_column\": color_selector.value,\n",
    "        \"size_column\": size_selector.value,\n",
    "        \"opacity_column\": opacity_selector.value,\n",
    "        \"color_transform\": color_transform_selector.value,\n",
    "        \"size_transform\": size_transform_selector.value,\n",
    "        \"opacity_transform\": opacity_transform_selector.value\n",
    "    }\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(cfg, f)\n",
    "    print(\"[Cell1] Configuration saved to\", config_file, \":\", cfg)\n",
    "\n",
    "save_button = widgets.Button(description=\"Save Config\", button_style=\"success\")\n",
    "save_button.on_click(on_save_config)\n",
    "display(save_button)\n",
    "\n",
    "print(\"Adjust columns/transforms as desired, then click 'Save Config'. Next, run Cell 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Load & Apply Config"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054154a174ba4171ae8a324d5a30e497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Load & Apply Config', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ef83565b5d4a9eae23c6698f53fd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Min/Max Ranges after transform"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8ffab6f9634a3586b85003651eeefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=0.0, description='Color Min:', layout=Layout(width='200px')), FloatText(value=0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229d0d62afa24125a5d0574540753f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=0.0, description='Size Min:', layout=Layout(width='200px')), FloatText(value=0.â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddc50df2eab43e18f0c2b0747a34e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatText(value=0.0, description='Opac Min:', layout=Layout(width='200px')), FloatText(value=0.â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'Load & Apply Config' to re-apply transforms, then see updated min/max here.\n"
     ]
    }
   ],
   "source": [
    "# === CELL 2: Load & Apply Config, then show min/max range ===\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "load_output = widgets.Output()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def apply_transform_with_5pct(series, transform_kind=\"None\"):\n",
    "    \"\"\"\n",
    "    1) Fill NaN with 0.\n",
    "    2) Replace zeros with the 5% quantile of positive values.\n",
    "    3) If transform='None', keep negatives as is.\n",
    "       If transform='log2' or 'log10', raise ValueError if still any negative values remain.\n",
    "    \"\"\"\n",
    "    s = series.fillna(0).copy()\n",
    "    \n",
    "    # Identify positive (non-zero) values to compute the 5% quantile\n",
    "    pos_mask = (s > 0)\n",
    "    if pos_mask.any():\n",
    "        # 5% quantile among the positive subset\n",
    "        q5 = np.quantile(s[pos_mask], 0.05)\n",
    "    else:\n",
    "        # If we have no positive data at all, let's fallback to something small\n",
    "        q5 = 1e-6  # or raise an error\n",
    "    if q5 <= 0:\n",
    "        # If the 5% quantile is not strictly positive, fallback to small epsilon\n",
    "        q5 = 1e-6\n",
    "\n",
    "    # Replace zeros with q5\n",
    "    zero_mask = (s == 0)\n",
    "    if zero_mask.any():\n",
    "        s[zero_mask] = q5\n",
    "\n",
    "    # If transform=None, we keep negative values as is\n",
    "    if transform_kind == \"None\":\n",
    "        return s\n",
    "\n",
    "    # If log2 or log10, raise error if data still has negative values\n",
    "    if (s < 0).any():\n",
    "        raise ValueError(\n",
    "            f\"Non-positive data found for {transform_kind} transform (some negative). \"\n",
    "            \"Check your data or use None transform.\"\n",
    "        )\n",
    "    \n",
    "    if transform_kind == \"log2\":\n",
    "        return np.log2(s)\n",
    "    elif transform_kind == \"log10\":\n",
    "        return np.log10(s)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid transform option: {transform_kind}\")\n",
    "    \n",
    "    \n",
    "# We'll define float text boxes for the final min/max\n",
    "color_min_box = widgets.FloatText(description=\"Color Min:\", layout={'width': '200px'})\n",
    "color_max_box = widgets.FloatText(description=\"Color Max:\", layout={'width': '200px'})\n",
    "size_min_box  = widgets.FloatText(description=\"Size Min:\",  layout={'width': '200px'})\n",
    "size_max_box  = widgets.FloatText(description=\"Size Max:\",  layout={'width': '200px'})\n",
    "opac_min_box  = widgets.FloatText(description=\"Opac Min:\", layout={'width': '200px'})\n",
    "opac_max_box  = widgets.FloatText(description=\"Opac Max:\", layout={'width': '200px'})\n",
    "\n",
    "def on_load_apply_config(b):\n",
    "    with load_output:\n",
    "        load_output.clear_output()\n",
    "        try:\n",
    "            if not os.path.exists(\"config.json\"):\n",
    "                print(\"No config.json found. Please run Cell 1 and save config.\")\n",
    "                return\n",
    "\n",
    "            with open(\"config.json\",\"r\") as f:\n",
    "                final_cfg = json.load(f)\n",
    "\n",
    "            # Extract columns & transforms\n",
    "            ccol = final_cfg.get(\"color_column\",\"scaled_PEAKavg\")\n",
    "            scol = final_cfg.get(\"size_column\",\"spoc_score\")\n",
    "            ocol = final_cfg.get(\"opacity_column\",\"spoc_score\")\n",
    "\n",
    "            cx = final_cfg.get(\"color_transform\",\"None\")\n",
    "            sx = final_cfg.get(\"size_transform\",\"None\")\n",
    "            ox = final_cfg.get(\"opacity_transform\",\"None\")\n",
    "\n",
    "            # Apply transforms\n",
    "            merged_df[\"color_processed\"] = apply_transform_with_5pct(merged_df[ccol], cx)\n",
    "            merged_df[\"size_processed\"]  = apply_transform_with_5pct(merged_df[scol], sx)\n",
    "            merged_df[\"opacity_processed\"] = apply_transform_with_5pct(merged_df[ocol], ox)\n",
    "\n",
    "            # Show new min/max\n",
    "            cmin, cmax = merged_df[\"color_processed\"].min(), merged_df[\"color_processed\"].max()\n",
    "            smin, smax = merged_df[\"size_processed\"].min(), merged_df[\"size_processed\"].max()\n",
    "            omin, omax = merged_df[\"opacity_processed\"].min(), merged_df[\"opacity_processed\"].max()\n",
    "\n",
    "            color_min_box.value, color_max_box.value = cmin, cmax\n",
    "            size_min_box.value, size_max_box.value   = smin, smax\n",
    "            opac_min_box.value, opac_max_box.value   = omin, omax\n",
    "\n",
    "            print(\"[Cell2] Loaded config:\", final_cfg)\n",
    "            print(f\" color_processed => [{cmin:.3f}..{cmax:.3f}]\")\n",
    "            print(f\" size_processed  => [{smin:.3f}..{smax:.3f}]\")\n",
    "            print(f\" opacity_processed => [{omin:.3f}..{omax:.3f}]\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(\"Error in transform:\", e)\n",
    "\n",
    "load_button = widgets.Button(description=\"Load & Apply Config\", button_style=\"primary\")\n",
    "load_button.on_click(on_load_apply_config)\n",
    "\n",
    "display(Markdown(\"### Load & Apply Config\"))\n",
    "display(load_button)\n",
    "display(load_output)\n",
    "\n",
    "display(Markdown(\"### Min/Max Ranges after transform\"))\n",
    "display(widgets.HBox([color_min_box, color_max_box]))\n",
    "display(widgets.HBox([size_min_box, size_max_box]))\n",
    "display(widgets.HBox([opac_min_box, opac_max_box]))\n",
    "\n",
    "print(\"Press 'Load & Apply Config' to re-apply transforms, then see updated min/max here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'color_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 23\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Optionally clamp or remap. For demonstration, let's just proceed as is.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 4) Build the final scatter. We'll show original columns in hover & legend\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     14\u001b[0m chart_title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBubble Chart\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[1;32m     17\u001b[0m     merged_df,\n\u001b[1;32m     18\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaled_PEAKavg\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# or whichever x-axis\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPTMavg\u001b[39m\u001b[38;5;124m\"\u001b[39m,          \u001b[38;5;66;03m# y-axis\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Show the original columns in hover\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     hover_data\u001b[38;5;241m=\u001b[39m[\u001b[43mcolor_col\u001b[49m, size_col, opacity_col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhover_text\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m     24\u001b[0m     title\u001b[38;5;241m=\u001b[39mchart_title,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# We can pick a color scale & range if desired\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     color_continuous_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     range_color\u001b[38;5;241m=\u001b[39m[cmin, cmax],  \u001b[38;5;66;03m# or override if you like\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     labels\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Rename color axis to original column name\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m: color_col,\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m: size_col\n\u001b[1;32m     32\u001b[0m     }\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplotly_white\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# We'll create a FigureWidget to attach advanced interactions\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'color_col' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.graph_objs import FigureWidget\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "import os, datetime\n",
    "\n",
    "# Optionally clamp or remap. For demonstration, let's just proceed as is.\n",
    "\n",
    "###############################################################################\n",
    "# 4) Build the final scatter. We'll show original columns in hover & legend\n",
    "###############################################################################\n",
    "chart_title = \"Bubble Chart\"\n",
    "\n",
    "fig = px.scatter(\n",
    "    merged_df,\n",
    "    x=\"scaled_PEAKavg\",   # or whichever x-axis\n",
    "    y=\"IPTMavg\",          # y-axis\n",
    "    color=\"color_processed\",\n",
    "    size=\"size_processed\",\n",
    "    # Show the original columns in hover\n",
    "    hover_data=[color_col, size_col, opacity_col, \"hover_text\"], \n",
    "    title=chart_title,\n",
    "    # We can pick a color scale & range if desired\n",
    "    color_continuous_scale=\"viridis\",\n",
    "    range_color=[cmin, cmax],  # or override if you like\n",
    "    labels={\n",
    "        # Rename color axis to original column name\n",
    "        \"color_processed\": color_col,\n",
    "        \"size_processed\": size_col\n",
    "    }\n",
    ")\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "\n",
    "# We'll create a FigureWidget to attach advanced interactions\n",
    "figw_dynamic = FigureWidget(fig)\n",
    "\n",
    "# We want per-point marker opacity from \"opacity_processed\"\n",
    "# but must clamp or map them to [0..1] for valid Plotly marker opacity\n",
    "def remap_to_01(array, old_min, old_max):\n",
    "    if np.isclose(old_max, old_min):\n",
    "        return np.full_like(array, 0.5)\n",
    "    return (array - old_min)/(old_max - old_min)\n",
    "\n",
    "op_min, op_max = merged_df[\"opacity_processed\"].min(), merged_df[\"opacity_processed\"].max()\n",
    "op_vals = merged_df[\"opacity_processed\"].values\n",
    "mapped_opacity = remap_to_01(op_vals, op_min, op_max)\n",
    "mapped_opacity = np.clip(mapped_opacity, 0, 1)  # final clamp\n",
    "\n",
    "for trace in figw_dynamic.data:\n",
    "    trace.marker.opacity = mapped_opacity\n",
    "\n",
    "###############################################################################\n",
    "# 5) ADVANCED FEATURES: search, highlight, persistent labels, saving\n",
    "###############################################################################\n",
    "\n",
    "# 5a) Global set for persistent selection\n",
    "global_persisted_indices_dynamic = set()\n",
    "\n",
    "def handle_selection_dynamic(trace, points, selector):\n",
    "    global global_persisted_indices_dynamic\n",
    "    global_persisted_indices_dynamic.update(points.point_inds)\n",
    "    if not global_persisted_indices_dynamic:\n",
    "        print(\"[Dynamic] No points selected.\")\n",
    "        return\n",
    "    print(\"[Dynamic] Accumulated selected indices:\", global_persisted_indices_dynamic)\n",
    "    selected_df = merged_df.iloc[list(global_persisted_indices_dynamic)]\n",
    "    \n",
    "    # Example label: short uniprot name from 'NAME' or just name\n",
    "    def short_label(name_str):\n",
    "        try:\n",
    "            # Something from SPOC code: parse after _vs_\n",
    "            parts = name_str.split(\"_vs_\")\n",
    "            if len(parts) < 2:\n",
    "                return name_str\n",
    "            hit = parts[1]\n",
    "            # parse short\n",
    "            hit_parts = hit.split(\"-\")\n",
    "            if len(hit_parts) < 3:\n",
    "                return hit\n",
    "            return hit_parts[2].split(\"_\")[0]\n",
    "        except:\n",
    "            return name_str\n",
    "    \n",
    "    labels = selected_df[\"NAME\"].apply(short_label)\n",
    "    \n",
    "    persistent_trace = None\n",
    "    for t in figw_dynamic.data:\n",
    "        if t.name == \"Persistent Labels (Dynamic)\":\n",
    "            persistent_trace = t\n",
    "            break\n",
    "    \n",
    "    if persistent_trace is None:\n",
    "        figw_dynamic.add_scatter(\n",
    "            x=selected_df[\"scaled_PEAKavg\"],\n",
    "            y=selected_df[\"IPTMavg\"],\n",
    "            mode=\"text\",\n",
    "            text=labels,\n",
    "            textposition=\"top center\",\n",
    "            name=\"Persistent Labels (Dynamic)\",\n",
    "            hoverinfo=\"skip\",\n",
    "            textfont=dict(color=\"black\", size=12)\n",
    "        )\n",
    "    else:\n",
    "        persistent_trace.x = selected_df[\"scaled_PEAKavg\"]\n",
    "        persistent_trace.y = selected_df[\"IPTMavg\"]\n",
    "        persistent_trace.text = labels\n",
    "\n",
    "# Attach selection callback\n",
    "for trace in figw_dynamic.data:\n",
    "    trace.on_selection(handle_selection_dynamic)\n",
    "\n",
    "# 5b) SEARCH: partial name => highlight\n",
    "search_input_dynamic = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"Enter partial NAME to search\",\n",
    "    description=\"Search NAME:\",\n",
    "    layout={'width': '300px'}\n",
    ")\n",
    "search_button_dynamic = widgets.Button(description=\"Search\", button_style=\"primary\")\n",
    "clear_search_button_dynamic = widgets.Button(description=\"Clear Search\", button_style=\"warning\")\n",
    "\n",
    "def on_search_button_click_dynamic(b):\n",
    "    query = search_input_dynamic.value.strip()\n",
    "    if not query:\n",
    "        print(\"[Dynamic] Please enter a search query.\")\n",
    "        return\n",
    "    mask = merged_df[\"NAME\"].str.contains(query, case=False, na=False)\n",
    "    matched = merged_df[mask]\n",
    "    if matched.empty:\n",
    "        print(\"[Dynamic] No matches found.\")\n",
    "        return\n",
    "    figw_dynamic.add_scatter(\n",
    "        x=matched[\"scaled_PEAKavg\"],\n",
    "        y=matched[\"IPTMavg\"],\n",
    "        mode=\"markers+text\",\n",
    "        marker=dict(symbol=\"circle-open\", size=12, line=dict(width=2, color=\"red\")),\n",
    "        text=[query]*len(matched),\n",
    "        textposition=\"top center\",\n",
    "        name=\"Search Highlight (Dynamic)\",\n",
    "        hoverinfo=\"skip\"\n",
    "    )\n",
    "    print(f\"[Dynamic] Found {len(matched)} matches. Highlights added.\")\n",
    "\n",
    "def on_clear_search_button_click_dynamic(b):\n",
    "    to_remove = [i for i, t in enumerate(figw_dynamic.data) if t.name == \"Search Highlight (Dynamic)\"]\n",
    "    if not to_remove:\n",
    "        print(\"[Dynamic] No highlights to clear.\")\n",
    "        return\n",
    "    for idx in sorted(to_remove, reverse=True):\n",
    "        figw_dynamic.data = figw_dynamic.data[:idx] + figw_dynamic.data[idx+1:]\n",
    "    print(\"[Dynamic] Search highlights cleared.\")\n",
    "\n",
    "search_button_dynamic.on_click(on_search_button_click_dynamic)\n",
    "clear_search_button_dynamic.on_click(on_clear_search_button_click_dynamic)\n",
    "\n",
    "# 5c) MULTI-GROUP HIGHLIGHT\n",
    "group_highlight_input_dynamic = widgets.Text(\n",
    "    value=\"(1,5=green) (2,9=red)\",\n",
    "    placeholder=\"(1,5=green) (2,9=red)\",\n",
    "    description=\"Multi-Groups:\",\n",
    "    layout={'width': '600px'}\n",
    ")\n",
    "group_highlight_button_dynamic = widgets.Button(\n",
    "    description=\"Highlight Groups\",\n",
    "    tooltip=\"Highlight multiple index groups, each with a color\",\n",
    "    button_style=\"info\"\n",
    ")\n",
    "\n",
    "def on_group_highlight_button_click_dynamic(b):\n",
    "    user_str = group_highlight_input_dynamic.value.strip()\n",
    "    if not user_str:\n",
    "        print(\"[Dynamic] No group spec. Format: (1,5=red) (2,9=blue)\")\n",
    "        return\n",
    "    group_specs = [chunk.strip() for chunk in user_str.split(\")\") if chunk.strip()]\n",
    "    for spec in group_specs:\n",
    "        if spec.startswith(\"(\"):\n",
    "            spec = spec[1:].strip()\n",
    "        if \"=\" in spec:\n",
    "            left, c = spec.split(\"=\", 1)\n",
    "            idx_str = left.strip()\n",
    "            color_str = c.strip()\n",
    "        else:\n",
    "            idx_str = spec\n",
    "            color_str = \"red\"\n",
    "        idx_list = [x.strip() for x in idx_str.split(\",\") if x.strip()]\n",
    "        matched = merged_df[merged_df[\"index\"].isin(idx_list)]\n",
    "        if matched.empty:\n",
    "            print(f\"[Dynamic] No match for indices {idx_list}.\")\n",
    "            continue\n",
    "        \n",
    "        # Example label from 'protein_name_hit' or short uniprot name. We'll just use 'NAME' here\n",
    "        group_label = matched[\"NAME\"] \n",
    "        figw_dynamic.add_scatter(\n",
    "            x=matched[\"scaled_PEAKavg\"],\n",
    "            y=matched[\"IPTMavg\"],\n",
    "            mode=\"markers+text\",\n",
    "            marker=dict(symbol=\"circle\", color=color_str, size=12),\n",
    "            text=group_label,\n",
    "            textposition=\"top center\",\n",
    "            name=\"Highlight (Dynamic)\",\n",
    "            hoverinfo=\"skip\"\n",
    "        )\n",
    "        print(f\"[Dynamic] Highlighted indices {idx_list} in '{color_str}'.\")\n",
    "    print(\"[Dynamic] Group highlight done.\")\n",
    "\n",
    "group_highlight_button_dynamic.on_click(on_group_highlight_button_click_dynamic)\n",
    "\n",
    "# 5d) CLEAR LABELS & HIGHLIGHTS\n",
    "clear_labels_button_dynamic = widgets.Button(description=\"Clear Labels\", button_style=\"warning\")\n",
    "def on_clear_labels_click_dynamic(b):\n",
    "    global_persisted_indices_dynamic.clear()\n",
    "    remove_names = [\"Persistent Labels (Dynamic)\", \"Highlight (Dynamic)\", \"Search Highlight (Dynamic)\"]\n",
    "    idx_remove = [i for i,t in enumerate(figw_dynamic.data) \n",
    "                  if t.name in remove_names or t.name.startswith(\"Highlight \")]\n",
    "    for idx in sorted(idx_remove, reverse=True):\n",
    "        figw_dynamic.data = figw_dynamic.data[:idx] + figw_dynamic.data[idx+1:]\n",
    "    print(\"[Dynamic] Cleared labels/highlights.\")\n",
    "\n",
    "clear_labels_button_dynamic.on_click(on_clear_labels_click_dynamic)\n",
    "\n",
    "# 5e) SAVE PLOT\n",
    "custom_suffix_dynamic = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"File name suffix\",\n",
    "    description=\"File Suffix:\",\n",
    "    layout={'width': '300px'}\n",
    ")\n",
    "save_plot_button_dynamic = widgets.Button(description=\"Save Plot (HTML & PDF)\", button_style=\"info\")\n",
    "\n",
    "def on_save_plot_click_dynamic(b):\n",
    "    try:\n",
    "        suffix = custom_suffix_dynamic.value.strip()\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if suffix:\n",
    "            suffix_str = f\"_{suffix}_{timestamp}\"\n",
    "        else:\n",
    "            suffix_str = f\"_{timestamp}\"\n",
    "\n",
    "        html_name = f\"spoc_bubble_chart{suffix_str}.html\"\n",
    "        pdf_name  = f\"spoc_bubble_chart{suffix_str}.pdf\"\n",
    "        html_path = os.path.join(output_dir, html_name)\n",
    "        pdf_path  = os.path.join(output_dir, pdf_name)\n",
    "\n",
    "        figw_dynamic.write_html(html_path)\n",
    "        figw_dynamic.write_image(pdf_path, format=\"pdf\")\n",
    "        print(f\"[Dynamic] Plot saved:\\n  HTML: {html_path}\\n  PDF: {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"[Dynamic] Error saving plot:\", e)\n",
    "\n",
    "save_plot_button_dynamic.on_click(on_save_plot_click_dynamic)\n",
    "\n",
    "# 5f) SAVE SELECTED DATA\n",
    "file_name_widget_dynamic = widgets.Text(\n",
    "    value=\"selected_data_dynamic.csv\",\n",
    "    placeholder=\"Enter file name\",\n",
    "    description=\"Save CSV as:\",\n",
    "    layout={'width': '300px'}\n",
    ")\n",
    "save_data_button_dynamic = widgets.Button(description=\"Save Data\", button_style=\"success\")\n",
    "save_data_output_dynamic = widgets.Output()\n",
    "\n",
    "def on_save_data_click_dynamic(b):\n",
    "    with save_data_output_dynamic:\n",
    "        save_data_output_dynamic.clear_output()\n",
    "        if not global_persisted_indices_dynamic:\n",
    "            print(\"[Dynamic] No points selected!\")\n",
    "            return\n",
    "        selected_df = merged_df.iloc[list(global_persisted_indices_dynamic)]\n",
    "        out_file = file_name_widget_dynamic.value\n",
    "        full_path = os.path.join(output_dir, out_file)\n",
    "        selected_df.to_csv(full_path, index=False)\n",
    "        print(f\"[Dynamic] Selected data saved to: {full_path}\")\n",
    "\n",
    "save_data_button_dynamic.on_click(on_save_data_click_dynamic)\n",
    "\n",
    "###############################################################################\n",
    "# 6) Display final UI\n",
    "###############################################################################\n",
    "instructions_text = \"\"\"\n",
    "**Instructions**:\n",
    "1. Lasso/Box select points => persistent labels.\n",
    "2. Search by partial `NAME` => highlight.\n",
    "3. Group highlight => e.g. `(1,5=green) (2,9=red)`.\n",
    "4. Clear labels/highlights as needed.\n",
    "5. Save the plot or the selected data.\n",
    "\"\"\"\n",
    "display(Markdown(instructions_text))\n",
    "# Search & highlight\n",
    "display(widgets.HBox([search_input_dynamic, search_button_dynamic, clear_search_button_dynamic]))\n",
    "display(widgets.HBox([group_highlight_input_dynamic, group_highlight_button_dynamic, clear_labels_button_dynamic]))\n",
    "# Suffix & save\n",
    "display(widgets.HBox([custom_suffix_dynamic, save_plot_button_dynamic]))\n",
    "# Show figure\n",
    "display(figw_dynamic)\n",
    "# CSV saving\n",
    "display(Markdown(\"#### Save Selected Data\"))\n",
    "display(widgets.HBox([file_name_widget_dynamic, save_data_button_dynamic]))\n",
    "display(save_data_output_dynamic)\n",
    "\n",
    "print(\"Done. Negative or zero data are handled by replacing zeros with 5% quantile, transform if valid, etc.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ms_analysis",
   "language": "python",
   "name": "ms_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
